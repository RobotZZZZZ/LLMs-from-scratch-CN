{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:15:09.585474Z",
     "start_time": "2025-04-27T12:15:07.687056Z"
    }
   },
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch06\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\project\\LLMs-from-scratch-CN\\ch06\\01_main-chapter-code\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # 用于加载OpenAI的预训练权重的TensorFlow库\n",
    "        \"pandas\"      # 用于加载数据集的库\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "#查看版本号Ω"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:10.680106Z",
     "start_time": "2025-04-27T12:20:10.676203Z"
    }
   },
   "source": [
    "# 防止某些单元格执行两次\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "executed_cells = set()\n",
    "#使用一个 set 数据结构来存储已经执行过的单元格标识符\n",
    "@register_line_cell_magic\n",
    "#注册了一个名为 run_once 的魔法命令\n",
    "def run_once(line, cell):\n",
    "    if line not in executed_cells:\n",
    "        get_ipython().run_cell(cell)\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:00.113812Z",
     "start_time": "2025-04-27T12:19:58.309973Z"
    }
   },
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "# 下载数据\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "    \n",
    "    # 下载文件\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    \n",
    "    # 解压文件\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    \n",
    "    # 添加.tsv扩展名\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:03.922602Z",
     "start_time": "2025-04-27T12:20:03.438431Z"
    }
   },
   "source": [
    "# 数据加载\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:06.061483Z",
     "start_time": "2025-04-27T12:20:06.037065Z"
    }
   },
   "source": [
    "df[\"Label\"].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:17.051077Z",
     "start_time": "2025-04-27T12:20:16.972352Z"
    }
   },
   "source": [
    "%%run_once balance_df\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    # 下采样，以使正负样本数量相等\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:20.275337Z",
     "start_time": "2025-04-27T12:20:20.230358Z"
    }
   },
   "source": [
    "%%run_once label_mapping\n",
    "\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:22.693912Z",
     "start_time": "2025-04-27T12:20:22.685836Z"
    }
   },
   "source": [
    "balanced_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:20:25.091631Z",
     "start_time": "2025-04-27T12:20:25.033329Z"
    }
   },
   "source": [
    "# 数据集划分\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 根据给定的比例，计算划分索引\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # 划分数据集\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 91, 437, 1659, 5239, 10163, 91, 29]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # 编码输入数据\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        # 最大长度截断\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encode_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        # 填充\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # qkv向量是否使用Bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# 上下文长度应小于max_length\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 32.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:02<00:00, 438kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 48.2kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:35<00:00, 3.20MiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 3.95MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 535kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 266kiB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "# 下载预训练模型权重\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 添加分类头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换输出层，用于分类\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除了输出层外，令trf的最后一个模块和final_norm的参数可训练\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Do'\n",
      "' you'\n",
      "' have'\n",
      "' time'\n"
     ]
    }
   ],
   "source": [
    "for token_id in inputs[0].tolist():\n",
    "    word = tokenizer.decode([token_id])\n",
    "    print(f\"'{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "# (batch_size, seq_len, num_classes)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# 最后一个输出，包含有最完整的信息\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# 若只想要分类结果，则可以跳过softmax操作\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分类准备率\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # 将数据移到指定设备\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            # 模型预估\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            # 获取分类结果\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            # 统计总样本量、分类正确样本量\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# 计算不同数据集上的准确率\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义batch训练损失\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    # 只关注最后一个输出\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    # 交叉熵损失\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义loader训练损失\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if i < num_batches:\n",
    "                loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "                total_loss += loss.item()\n",
    "            else:\n",
    "                break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.937\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "# 查看训练前，各数据集上的损失表现\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 在有监督数据上微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练过程\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 初始化梯度\n",
    "            optimizer.zero_grad()\n",
    "            # loss计算\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 权重更新\n",
    "            optimizer.step()\n",
    "            \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}) \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy * 100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000) Train loss 2.273, Val loss 2.524\n",
      "Ep 1 (Step 000050) Train loss 1.242, Val loss 1.249\n",
      "Ep 1 (Step 000100) Train loss 0.667, Val loss 0.704\n",
      "Training accuracy: 55.00% | Validation accuracy: 55.00%\n",
      "Ep 2 (Step 000150) Train loss 0.690, Val loss 0.692\n",
      "Ep 2 (Step 000200) Train loss 0.679, Val loss 0.679\n",
      "Ep 2 (Step 000250) Train loss 0.683, Val loss 0.674\n",
      "Training accuracy: 67.50% | Validation accuracy: 75.00%\n",
      "Ep 3 (Step 000300) Train loss 0.670, Val loss 0.669\n",
      "Ep 3 (Step 000350) Train loss 0.665, Val loss 0.668\n",
      "Training accuracy: 70.00% | Validation accuracy: 62.50%\n",
      "Ep 4 (Step 000400) Train loss 0.614, Val loss 0.667\n",
      "Ep 4 (Step 000450) Train loss 0.651, Val loss 0.655\n",
      "Ep 4 (Step 000500) Train loss 0.658, Val loss 0.651\n",
      "Training accuracy: 90.00% | Validation accuracy: 77.50%\n",
      "Ep 5 (Step 000550) Train loss 0.648, Val loss 0.645\n",
      "Ep 5 (Step 000600) Train loss 0.668, Val loss 0.644\n",
      "Training accuracy: 85.00% | Validation accuracy: 75.00%\n",
      "Training completed in 0.74 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 2))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAC+CAYAAACf6L4QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1V0lEQVR4nO3dB3hTZdsH8H9WFy1t2ZRdgbL3ENmyQQREcfBhRV5RQEUZKg6GrwouwIHIEPBVAUUBkY1skCF7761sKLR0JjnfdT9p0rSsFtqM5v+7POack/Tk6UOa+zxbp2maBiIiIspR+py9PBEREQkGXCIiIhdgwCUiInIBBlwiIiIXYMAlIiJyAQZcIiIiF2DAJSIicgEGXCIiIhdgwCUiInIBBlwiIiIXYMBNNW7cOJQuXRoBAQGoX78+Nm/ejNxozZo16NixIyIiIqDT6TB37tx0z8tMn0OHDkXRokURGBiIli1b4vDhw+lec+XKFXTv3h158+ZFWFgYevXqhbi4uHSv2bVrFxo3bqzys0SJEvjkk0/gLUaOHIm6desiJCQEhQoVQufOnXHw4MF0r0lMTES/fv2QP39+BAcHo2vXrjh//ny615w6dQodOnRAUFCQus7gwYNhNpvTvWbVqlWoVasW/P39UbZsWUybNg3eYPz48ahWrZr6DMjWoEEDLFq0yPG8r+fPrYwaNUr9zb322muOc8wnYPjw4SpfnLcKFSrkzjySuZR93cyZMzU/Pz9typQp2t69e7UXXnhBCwsL086fP6/lNgsXLtTeeecdbfbs2TKHtjZnzpx0z48aNUoLDQ3V5s6dq+3cuVN79NFHtTJlymgJCQmO17Rt21arXr26tnHjRm3t2rVa2bJltaefftrx/LVr17TChQtr3bt31/bs2aPNmDFDCwwM1CZMmKB5gzZt2mhTp05Vad+xY4fWvn17rWTJklpcXJzjNS+99JJWokQJbfny5dqWLVu0Bx98UHvooYccz5vNZq1KlSpay5Ytte3bt6t8L1CggDZkyBDHa44dO6YFBQVpAwYM0Pbt26d99dVXmsFg0BYvXqx5unnz5mkLFizQDh06pB08eFB7++23NZPJpPJM+Hr+ZLR582atdOnSWrVq1bT+/fs7zjOfNG3YsGFa5cqVtbNnzzq2ixcv5so8YsDVNK1evXpav379HMcWi0WLiIjQRo4cqeVmGQOu1WrVihQpon366aeOczExMZq/v78KmkI+rPJzf//9t+M1ixYt0nQ6nfbPP/+o42+++UYLDw/XkpKSHK958803taioKM0bXbhwQf3Oq1evduSJBJdZs2Y5XrN//371mg0bNqhj+aPX6/XauXPnHK8ZP368ljdvXke+vPHGG+qLxtmTTz6pAr43kn/zyZMnM38yiI2N1cqVK6ctW7ZMa9q0qSPgMp/SAq7cwN9Kbssjn69STk5OxtatW1XVqZ1er1fHGzZsgC85fvw4zp07ly4vQkNDVRW7PS/kUaqR69Sp43iNvF7ybNOmTY7XNGnSBH5+fo7XtGnTRlXLXr16Fd7m2rVr6jFfvnzqUT4vKSkp6fJJqsBKliyZLp+qVq2KwoULp8uD69evY+/evY7XOF/D/hpv+9xZLBbMnDkTN27cUFXLzJ/0pDpUqjsz/i7MpzTSbCXNXJGRkaq5SqqIc2Me+XzAvXTpkvrCcP7HEnIswceX2H/fO+WFPEobiTOj0aiCkfNrbnUN5/fwFlarVbW5NWzYEFWqVHH8DnIzITced8qnu+XB7V4jXxQJCQnwdLt371ZtatIm9tJLL2HOnDmoVKkS88eJ3Ihs27ZN9QvIiPlkIzf00p66ePFi1TdAbvyl/0dsbGyuyyOjy96JyAtJ6WTPnj1Yt26du5PicaKiorBjxw5VA/Drr78iOjoaq1evdneyPMbp06fRv39/LFu2THUepFtr166dY1864kkALlWqFH755RfVcTM38fkSboECBWAwGG7q9SbHRYoUgS+x/753ygt5vHDhQrrnpTeg9Fx2fs2truH8Ht7g5Zdfxvz587Fy5UoUL17ccV5+B2mKiImJuWM+3S0Pbvca6fXrDV80UvKQ3p61a9dWJbjq1avjiy++YP6kkupQ+VuRnrFSCySb3JB8+eWXal9KWMynm0lptnz58jhy5Eiu+yz5fMCVLw35wli+fHm6akQ5lvYoX1KmTBn1wXTOC6lykbZZe17Io3z45cvEbsWKFSrP5M7U/hoZfiRtL3Zyly8lovDwcHg66U8mwVaqSOV3k3xxJp8Xk8mULp+kfVranZzzSapcnW9OJA/kD1yqXe2vcb6G/TXe+rmTz0BSUhLzJ1WLFi3U7yi1APZN+j5IG6V9n/l0MxliePToUTU0Mdd9llzaRcuDhwVJT9xp06apXri9e/dWw4Kce73lFtJjUrrOyyb//KNHj1b7J0+edAwLkt/9999/13bt2qV16tTplsOCatasqW3atElbt26d6oHpPCxIehbKsKAePXqoYSKSv9Il31uGBfXp00cNjVq1alW6oQrx8fHphirIUKEVK1aooQoNGjRQW8ahCq1bt1ZDi2T4QcGCBW85VGHw4MGq5+W4ceO8ZjjHW2+9pXptHz9+XH1O5Fh6qi9dulQ97+v5czvOvZQF80nTBg4cqP7W5LO0fv16NbxHhvXI6IDclkcMuKlkXJb8o8p4XBkmJGNMc6OVK1eqQJtxi46OdgwNeu+991TAlJuQFi1aqHGWzi5fvqwCbHBwsOp637NnTxXInckY3kaNGqlrFCtWTAVyb3Gr/JFNxubayQ1I37591VAY+UPu0qWLCsrOTpw4obVr106NQZYvEPliSUlJuenfo0aNGupzFxkZme49PNnzzz+vlSpVSqVbvtzkc2IPtsLX8yezAZf5pKnhOUWLFlVpl+8KOT5y5EiuzCOd/M+1ZWoiIiLf4/NtuERERK7AgEtEROQCDLhEREQuwIBLRETkAgy4RERELsCAS0RE5AIMuERERC7AgJtKpqQbPny4eqRbYx5lDvPp7phHd8c8yn15xIkvnOYMlrVfZeUTmYOTbsY8yhzm090xj+6OeZT78oglXCIiIhdgwCUiInIBr16AXtZh3b59u1pXUq+/v3uH2NhY9fjPP/+oagq6GfMoc5hPd8c8ujvmkffkkSxNKevr1qxZU611nCvbcP/++2/Uq1fP3ckgIiLC5s2bUbdu3dxZwpWSrf2XlMWKiYiIXO3s2bOq8GePSbky4NqrkSXYFi9e3N3JISIiH6a/S9MmO005k9p1q9XdqSAiolyIAdfu1EZgantg2/fuTgkREeVCDLh2Z3cCp/4C1nwGmL1j1hIiIvIeXt2Gm61qRQPrxgLXzwDb/gfUe8HdKSKi+yADMGTooMVicXdSyMsZDAY13Een093XdRhw7UwBQOMBwMJBwNrPgZo9bOeIyOskJyernqPx8fHuTgrlEkFBQaqDrp+f3z1fgwHXWa1n00q5W6cBD77k7hQR0T1MQnD8+HFVKomIiFBfkPdbMiHfrilJTk7GxYsX1eeqXLly9zzREgOuM6M/0GQQMP81YN1ooHY0YAp0d6qIKAvky1GCbokSJVSphOh+BQYGwmQy4eTJk+rzFRBwb7Wf7DSVUY3uQFhJIO48sGWKu1NDRPfofqd7JcruzxM/kRkZ/YAmb9j2140Bkm+4O0VERJQLMODeSvWngPAywI2LwN+T3Z0aIqJ7Urp0aYwdOzbTr1+1apVq746JicnRdE2bNg1hYWHwNQy4t2IwAU3tpdyxQJJtRQoiopwgQe5O2/Dhw+95gZfevXtn+vUPPfSQ6t0ti7pT9mOnqdup2s02CcaVo8DmiUDjge5OERHlUhLk7H7++WcMHToUBw8edJwLDg5O12tWxhbfaRk4u4IFC2YpHdKju0iRIln6Gco8lnBT/ROTgCnrjqedMBiBZm/Z9jeM4+xTRJRjJMjZNyldSqnWfnzgwAGEhIRg0aJFqF27Nvz9/bFu3TocPXoUnTp1UivUSECWZeH+/PPPO1Ypy3UnT56MLl26qB7cMsRl3rx5t61Stlf9LlmyBBUrVlTv07Zt23Q3CDK5yKuvvqpelz9/frz55puIjo5G586ds5QH48ePxwMPPKCCflRUFH744Yd0NxlSyi9ZsqT6/WW4l7yn3TfffKN+F+k9LPnx+OOPwxMx4AKIiU9G2zFr8P78fVh7+GLaE1W6Ag/2A55baBsyREReSb6w45PNLt+yc7nxt956C6NGjcL+/ftRrVo1xMXFoX379li+fDm2b9+uAmHHjh1x6tSpO15nxIgR6NatG3bt2qV+vnv37rhy5cptXy+Th3z22WcqAK5Zs0Zdf9CgQY7nP/74Y/z000+YOnUq1q9frxaCnzt3bpZ+tzlz5qB///4YOHAg9uzZgxdffBE9e/bEypUr1fO//fYbxowZgwkTJuDw4cPq+lWrVlXPbdmyRQXf999/X9UKLF68GE2aNIEnYpUygLAgP3StXRzT/jqBd+bswdLXmyDAZAD0BqDtR+5OHhHdp4QUCyoNXeLy9933fhsE+WXP16wElFatWjmO8+XLh+rVqzuO//vf/6rAJSXWl19++bbXee655/D000+r/Y8++ghffvmlWlNcAvatpKSk4Ntvv1WlTyHXlrTYffXVVxgyZIgqNYuvv/4aCxcuzNLv9tlnn6l09e3bVx0PGDAAGzduVOebN2+ugryU9lu2bKnGw0pJV9afFfJcnjx58Mgjj6iagFKlSqFmzZrwRCzhphrUJgpF8gbg1JV4fLn88K1flHjd1ckiIlLq1KmT7lhKuFLSlKpeqc6V6l4p/d6thCulYzsJVHnz5sWFCxdu+3qperYHWyHTG9pff+3aNZw/f94R/ITM8CVV31mxf/9+NGzYMN05OZbz4oknnkBCQgIiIyPxwgsvqBsLqcoWchMiQVae69Gjhypte+qUnizhpgr2N2JEp8p48YetmLjmGB6tEYEKRfLanpReyoveBA4sAF7dDgTlc3dyiSgLAk0GVdp0x/tmFwmOziTYLlu2TJUCy5Ytq2ZDkrZLmQnpTqSE6EzabGVmrqy8PjuryjNDZg2T6mJpo5bfWUrCn376KVavXq1Ktdu2bVPtz0uXLlUdzqS9V3poe9rQI5ZwnbSpXAStKxWG2arh7dm7YbWmfqhMeWzL9yXGAAcXuTuZRJRFEiSkatfVW07O4SztpVINK1W50p4pVa4nTpyAK0kHL+mkJMHNTnpQSwDMiooVK6rfx5kcV6pUyXEsNxTSRi1V4BJcN2zYgN27d6vnpMe2VDd/8sknqm1a8mHFihXwNCzhZiCl3L+OXsa2UzGYvvkU/u/BUjKnF9Dhc0BvBIqnr9YhInIH6ZU7e/ZsFYQksL/33nt3LKnmlFdeeQUjR45UpewKFSqoNt2rV69m6WZj8ODBqiOXtL1K4Pzjjz/U72bvdS29pSWQ169fX1Vx//jjjyoAS1Xy/PnzcezYMdVRKjw8XLUfSz5IT2dPwxJuBkVDAzGodXm1//HiA7hwPdH2RMkHGWyJyGOMHj1aBRiZrEKCbps2bVCrVi2Xp0OGAUknrGeffRYNGjRQbcmSlqxM8N+5c2d88cUXqnq8cuXKqjey9Hpu1qyZel6qhidNmqTadaUNWgKxBGUZhiTPSXB++OGHVUlZOnjNmDFDXcfT6DRXV8ZnozNnzqi6/dOnT6N48eLZdl2LVcNj36zHzjPX0KFqUYzrnuFDfP2sbZgQ23KJPE5iYqJaRq1MmTL3vKoL3TspXUrgkxKr9Jz2hc/VmUzGIpZwb8Gg1+Gjx6qqxwW7z2LFgfNpT26aAHxR3bZIPRGRj5Ml66T0eejQIdWm2qdPHxWYnnnmGXcnzeMw4N5G5YhQ9GpURu2/N3evGsSu5IsELEnA398BsU6BmIjIR5etkzZWmelKqnwl6EqVr5RyyYMCrjS0yz+SdOsuVKiQqsd3nj/U3V5rWQ7FwgLVtI9jlh2ynSzbEiheFzAnAOszvwoHEVFuJFWp0qNYxuTKLFN//fWXx8705NMBV8ZQ9evXT80oImOrZEaT1q1b48YNz1iDVrr1f9C5itqfsv4E9vxzTcYXAM3ftr1ASrnSnktEROTJAVfmvJRxZNKbTKYok2oJmSVl69at8BTNKxRCh2pFVUeqt+fsVo+IbA6UbGCrWl432t1JJCIiL+BRbbhSJWGfI/RWkpKSVJWFfYuNdc06tcMeqYSQACN2nbmG/204kb6Uu3UacO2MS9JBRETeS+9JXclfe+011ehepYqtGvdWbb4ys4l9c56FJCcVyhuAN9tWUPufLTmIf2MSgDJNgFKNAEsyeywTEZH3BFxpy5VlmWbOnHnb18iKFFIKtm/79u1zWfqeqVcStUuF40ayBcPm7bWdbD7E9rjtByDmzhOGExGRb/OIgCvLPcn0XLL24Z0GDcvCw7KyhX2T3s2uopexuV2qwqjXYdm+81iy9xxQuhFQpilgTQHWfOaytBARkfdxa8CVSa4k2MpSSzLRtMzg4cmiioSgd5NItT/s972ITUxJa8vd8RNw5bh7E0hEPk2mQpSmObvSpUtj7Ng7D1+UOY+zumB8Tl7nTmQVoBo1asBb6d1djSyTUE+fPl2VVs+dO6c2WffQU73aohxK5Q/CueuJ+HzpIdscyw+0AKxmlnKJ6J7IXMi3WwB+7dq1KpjJKjhZJav49O7dG64IemfPnkW7du2y9b1yG7cG3PHjx6u2WLkrk0WN7dvPP/8MTxVgMuDDzlXV/vcbTmDH6Zi0Uu7ZHYD5zmtREhFl1KtXLzUXgczJm5FM4i+LzzsvHJ9ZBQsWVKvruIIsDyjNfuTBVcq32mRsridrVK4AutQsBln2Ycjs3TAXrQU8Ow94cQ1g9HN38ojIyzzyyCMqOMpcBM7i4uIwa9YsFZAvX76sVuUpVqyYCqKyBq6sinMnGauUDx8+rGaBksn3ZZSHBPlbrf5Tvnx59R6RkZFq2T+ZlEhI+kaMGIGdO3eqUrds9jRnrFKWKR5lBR9ZRk9W9endu7f6fezke15mF5QVgqSgJa+RWk/7e2V2dMv777+v+v5IsJeSt8zvYJecnKyaLeX68jvLcn4y2kVIrJHSesmSJdXPRkRE4NVXX0VO4nq49+idDhWx8uAF7D97HVPWH0fvJk3dnSQiupvke5jFzuAPGFK/Ki1m24Q3Oj1gCrzzdf3yZPotZAF1Wd5Ogtc777zjWEtWgq2sAyuBVoJV7dq1VUCUTqMLFixAjx498MADD6BevXqZCk6PPfaYWjB+06ZNqnbRub3XTpr3JB0SgCRovvDCC+rcG2+8gSeffFKNJpGgZl+rVoZoZiSzBcoSfbJcn1RrX7hwAf/5z39U8HO+qZCOshIM5fHIkSPq+hI05T0zQ5b0+/zzz9VyfrKW7pQpU/Doo49i7969ar1gWax+3rx5+OWXX1RgldV8ZBO//fYbxowZo0bGyORL0pwpNxI5iQH3HhUI9sfb7Srijd92Ycyyw2hXpShK5AsCUhKA42uB8q3dnUQiyuijiKz/zBPTgMpdbPsH/gBmPWcbg99zQdprxlYF4i+n/7nhtol8Muv555/Hp59+qqa8ta8DK9XJXbt2dcw9MGjQoHQLvy9ZskQFk8wEXAmQBw4cUD8jwVR89NFHN7W7vvvuu+lKyPKeEpQk4EppVda7lRsEqUK+HemXI8vZ/e9//0OePLYbj6+//lq1VX/88ccq6AtZz1fOGwwGtXh9hw4dsHz58kwHXCkdyw3IU089pY7l2hK8pVQ/btw4NXOhBN5GjRqpmxgp4drJc/I7yIL3JpNJBeTM5KPLq5TlDsG5rWHz5s3qTmnixInwJU/UKY56ZfIhIcWCob/vgZYQA3xZE5jeDbhwwN3JIyIvIgFHFpOXUpqQEp90mJLqZCElXVlfVqqSZTY+CXwSPCVwZMb+/fvVQgP2YCukBJqR9KGRCYgkGMl7SADO7Hs4v5dM12sPtqJhw4aqlO28QI2ULCXY2klpV0rDmSGzDf7777/qus7kWN7fXm29Y8cOREVFqeripUuXOl73xBNPqA66Um0uAV5Gy5jNqavCeVIJV9Y5lPp4qc6QYnirVq1Uxv3000/qeOjQofAFcsckY3Pbf7EWKw9exILDxfFI8TrAvzuAuHNAIdvsVETkId7+996qlO0qdLRdQ6qUnb22O9s6T0nJVUpnUrqV6uKmTW3NVVL6lSpUKb1J0JVgJgUdaafMLhs2bED37t1VO61UCUupWkq3Um2bE0wm003fqRKUs0utWrXU2ryLFi1SJfxu3bqpEu2vv/6qbj4k+Mt5acvu27evo4YhY7rcWsKVOnx70VuqM2QqRlmSSQJuxkb/3K5soWD0afaA2h/xxz5cb/EJ8Mo2INJWJUREHkTaVbO62dtvhezLOef229td9x5IQJD1ZaVKVqpjpZrZ3p4rS+B16tQJ//d//6dKj1Iyk0XfM0vWp5XaSRm+YycrtTmT73GpdpV2ZOkZLdWxssB8ul/Vz0+Vtu/2XtIe6rzy2/r169XvJqXN7CDt2FJal+s6k2PnaX/lddI2PGnSJFV6l7bbK1euqOekilyquaWtd9WqVeqGQ9qtc8o9BVzpRWbv/i13B9JIba8Scf7H9BV9mz+AyIJ5cDE2CaPWXmZPZSK6J1KFK8FBprGV71LnERsS/KQkJkFRqkxffPFFnD9/PtPXlpKd9D6Ojo5WwVCqqyWwOpP3kOpjKdUePXpUBSKpanUm7bpSapSq2kuXLqlFZTKSUrL0Cpb3kgKatKu+8sorqlbU3n6bHQYPHqzabSWQSmn1rbfeUunq37+/en706NGqJ7e0XcvNiXRCk6rysLAwVTj87rvvVPqOHTum5oSQAOzczusRAVeqj7/99lv1DyYfAPuAbalPl67dvsbfaFBVy2L6plPYevKKrTfj9h+Bc3vcnTwi8iJSrXz16lVVpevc3iptqVJFKuelU5UEDhlWk1lSupTgKe2WUkMpvYY//PDDdK+RwtPrr7+uehNLb2EJ7jIsyJl04pLv/ObNm6uhTLcamiRDiqR9WUqSdevWxeOPP44WLVqoDlLZSdplBwwYgIEDB6pqduk9Lb2S5cZBSO/qTz75RJXWJR0nTpzAwoULVV5I0JVSr7T5yhhnKTz+8ccfORrDdJoMRsoiKXp36dJFNVrLHYy9kf/tt99WdxKzZ8+GK0jHLamHl2qSO83B7CqDZ+3ErK1nUL5wMBZFLYJh83ggqj3w9J3HyhFR9pHesVICk6lipZRFlNOfq8zGonvqNCV3V1KVIAFXunXbSUcqV81q4onebl8Ryw9cwKHzcZhZviW66yYABxcC/2wDitVyd/KIiMiN7qlKWaokpN7eHmylUV16zkkdeqFCheCrwvP44b1HKqr9ERtSEFe+q+2JVaPcmzAiIvLOgCs95aQHnYiJiUH9+vVVt3FpT5D5kX1Z5xrF0KhsASSbrRh2rT00nQE4vAQ4s8XdSSMiIm8LuNu2bUPjxo3Vvoxnkl5nUsqVICy92nyZdOH/oHMV+Bv1+O2EP06VsPXgxsqP3J00IiLytoAbHx/vWPxdZu6Q+Tml19eDDz5405gtX1S6QB61jJ94+UxLaHojcHQ5cCr9mDciIvId9xRwy5Ytq1aFkB5Z0vW7dWvbvMEyJZcMMibghcaRqrfy7vhwbApNnauUpVwil7mHARhEOfp5uqeAK1M3yoTWMgBaxnPZ5+OU0q6s2ECAn1HvGJs78GxLWPUm4Phq4MQ6dyeNKFezT8snNXFE2cX+ebqfaR/vaViQDGKW1RdkJhSZYsxOBjbL+FyyqVM6H56pXxLTNwF/GFqik3URsHJk+lVGiChbyWT4MqmBfRJ8Gaponx6R6F5KthJs5fMknyvnxRZctjyfzHIim33VIBnsm9NLG3mjN9tWwLJ95zEytj06BP4J48l1wPE1QJkm7k4aUa5lXzousyvPEN2NBNs7LUmYYwFXVnP44IMP1FAgWRRZSCcqmV5L5uaUDlRkExpowrCOlfDy9CTMMD+MHoYltrbc0o2lS7O7k0eUK0mJVpZ6k3kBZO53ovsh1cj3U7K9r4ArQVUmfR41apRjLcJ169Zh+PDhavqrjPNz+roOVYvi16gz+Orgo+hk3ICQEg9CZzUDhpxZAoqIbORLMju+KImywz0F3O+//x6TJ092rBIkZPLnYsWKqTUFGXBvvtv+b6cqaD3mCuomfIn/htVBNwZbIiKfck91v7IChCzFl5Gcs68zSOmVyBeE11uVQxL88OHC/bgUd/OSVkRElHvdU8CVnsm3WmZJzklJl26tZ8MyqFg0L64lpGDGrJnA/AHSBc7dySIiIk+tUpb1BTt06KDWD7SPwd2wYYOaCEPWGqRbMxn0GPlYVTz7zVI8f2IwcDIJKNcKiEqdGIOIiHKteyrhNm3aFIcOHVJjbmXxAtlkese9e/fihx9+yP5U5iI1SoThsQaVMdnSAXONbZFYoLK7k0RERC5wTwvQ387OnTtRq1YtWCwW+OIC9JkVm5iCVqPX4Nz1RPRt9gDeaHtzezgREXmHzMYiDph1g5AAE4Y/aivZTlxzDAfPxbo7SURElMMYcN2kbZUiaFWpMMprx3Ft6uOw7pnr7iQREVEOYsB1oxGPVkYHv22ol7QR1xe/D1hdUxVPREQe3ktZOkbdiXSeosyLCAtEaLNXcW3VQoTFHcW1Lb8gtN7T7k4WERG5O+CGhobe9flnn332ftPkU55uWg0z/34M3eN/hHnJUJhL1YKxcJS7k0VERO4MuFOnTs3u9/d5Br0ONZ8YglPTlqKk5QJuTHgY5if/h4CoFu5OGhERZSO24XqASmWK41in37FdK4c81jgYZzyB2PWT3J0sIiLKRgy4HqJZrUpA9B9YgMYwwoKQZYNwbc4gdqQiIsolGHA9SM3IoqjYdwYmmZ5Rx6E7J6khQ0i87u6kERHRfWLA9TCRhULQ+dWxGBX8FhI1E0JPr0Dc+BbA1ZPuThoREd0HBlwPVDDEH6+8MhijiozBeS0MwdcOYf8fY9ydLCIiug8MuB4qj78R7/TujolRkzHV3AYd9zXHmGWHkI1TXxMRkQsx4Hr4cn7vPt0SV5v8F2YY8cXywxjy6zaYt/0EWK3uTh4REXlLwF2zZg06duyIiIgI6HQ6zJ3L+YQzknwZ0DoKH3apAr0OqLBzFIzz+iJlbj93J42IiLwl4N64cQPVq1fHuHHj3JkMr9C9filM6FEHh/SRSNJM+PR4GVyKS3J3soiIKCdmmspu7dq1UxtljqwulP8/b6Hj1Bo4dDEvloz/C9/3rIfS4X6AweTu5BERUW5pw01KSsL169cdW2ys760jW6tkOL7t2xEl8gXi5OV49P3mdySNrQ0cWODupBERUW4JuCNHjlQLJNi3SpUqwRdFFgzG7D4NUbVYKLolz4F/7EloM7sD678A2IuZiMgjeVXAHTJkCK5du+bY9u3bB18eqzuz94NYG/k6fjC3hA4asGwoMO9lwJzs7uQREZE3B1x/f3/kzZvXsYWEhMDXx+p+G/0gdlV7D8NSomHRdMD2H6H90BmIv+Lu5BERkbcGXLr1WN1PnqiO0Kb90CtlMGK1QOhOroc26WHg4iF3J4+IiDwh4MbFxWHHjh1qE8ePH1f7p06dcmeyvHasbutOPfBEynCcthaE7upxaJNbAEdXujt5RETk7oC7ZcsW1KxZU21iwIABan/o0KHuTJbXeqZ+SQz6vy54UvsAW6zloUu6Du3HrsDf37k7aUREPs+t43CbNWvGuYGzWUsZq/tCG/SZFoI3Ur7BY4Z1wIIBwKXDQOsPAINb/8mJiHwW23BzoZolwzGjbzOMDR6IT1K62U5uGg9s+MrdSSMi8lks7uRSZQrkwW99G+L5aX44frYonjctRVxoFzR3d8KIiHwUS7g+MFY3odwjeCLpXfSavhfTN52yTY7BHsxERC7FgOsDY3UnPVsH3eqUgFUD3p6zG39NGQzt24bArl/cnTwiIp/BgOsjY3U/7loNr7YoBx2suH5iB3SWZJiT492dNCIin8E2XF8aq9uqPIqGBqDfnP5obNkJ7K6EcVXNqhRMREQ5i9+0PubpeiVRKMQf/aYbkXjwIp6auBFTu0WiwOohQNkWgN5kW+pPb0x9lM2Qtm9/zj8EyP9A2oVvXJKwDgSEcugREdEt8JvRB7WoWBgzXngQvb7fgt3/XMO+ic+hiWUTsG9upq9hLVoDN6L/RGKKFYkpFhSZ2gym2NPY32E2LodVV+ci9k1Chb2jYdUZYdUZ1KNFNhjUoxkGmGF7TIHt+RhjQUyNGA6DXgejQYdHLkxC/pSz+KtId1wIrqCqx4vF70fly8ugGfxU8NdSbwJ0qTcEOjk2GNWjzuCnHjVjAK6VaGG7rl6H4LjjMJlvwBJaCro8+aDX6aAl34Ax/gKsmg6aTirf9dCkEj71WO3LOQ3q0SrnNB3MxmBYAVk+ArAkQ7NqsOr0sMKgzlk1Tf2MjDlPdyw/k7qv09mq/iVt6tEg6dTDJI8Zzpv0qc877dt/Vn4/qc0gIs/DgOvDY3V/6/MQoqdsxrtXn8LAgCCUzZMIndWsNlhToLeaodfSNoPaJFyasf+Mhp7Dlzqut84/AcV1wKDZ+7FXS1Tn+hpOoZLJAr1myXS6TiYUwoLdZx3Hz/utQxX9CYy5WBurrAHq3BOGDYg2Tc/S73tD80flpKmO42mmj9HMsBMDk1/Cb9Ym6lxL/VZM9vscWRWVOA1J8FP7o022yUY+SOmOyZYO6lwN3RHM9hsGqwrYtsDtCN4SgO2B3bHZjjsmfYBzyK+u0c8wF08aVuInS0tMsHRU54riMqb6fXLTz0pNg6bT2za5lk6vIrrsQ6fHN0F9cMGvmArojVLWo1nicuwJqIXlIZ3VjUeAlojelz+21Vio/2yPtgN1pPZtcT3tcXXh/8OFoHLqGpFx21Hr8jycD4rC5qLPqHNyI9D+2Adyu5V2HZ0eeh3gZzTA36iHv9EAP3k0GeBn0NuuXSsaKFHPltlndwF/TwLCSwONB6b9IywbBiTGOP2rON103HQDknpc6VEgspltP+Y0sHkikKcA0LB/2kt3zQLiL9tqbaRmx1HLY0hf4+OoETICeYsBYSVsP29JAWJOAXJzaD8nUhJt6ZLXp/773C+rVYNF02CRGz77oxU3nUv3vAbHjZrcuNluSO03fGnH8m/k7hs5i1VDktmCpBQrksy2G315VOfkUZ23qEJA2jnbY7pzqddINFsRGmjEB52ruux3YMD19bG6fR5Cr+9N6H/mBSDh3q4jX5Qd9OMRKDXNQUZEmYwIMOmx2/AU+hs6I8hgRZBRQ6DBikD1qCFQb4G/XkOAwYoAvQUmnQWwmJGiM2FE/spIsVjVH9g/53rjcuIlNAxviEp+RdS5gtfjse5KnOPmQCc3B5ptX5+679iscpOQgiSYUK1gKFIs8kVjRfKNcJyzFIRfnlAU1vnDYgWCNX/csAQ6QqI+XVi0Hdv20ytfOC/Mej/1pRQeZwSSgaJhgageFKbORaXkgf7qrX/2TkoXyIMALUiluXhyPEpaL6KgPgFBBgPMFg3+1hRU0J+++4VsyXc4f+ky9mq2lbYeMhxGHdNGHIkLwNpzjdS5YMRjQsA6ZNXnF+tgjdVf7T9p2InnTEux7OIlTDrSwPGa1/0XwV9nztJ1R+4vgG1hZoQH+aGhZTOiT/4P5/NWxdqgJ5Evj0mdr7rzZxjj0m7UMiVfZFrAjT0L/PUlEF4mfcCVc+d2ZemyV2v2w8labyA2MQXWS8fQdElrJBuCML7BGsQlpSA20Yxnj76OSvFbHD+T/kbM9umzn7N/AhfomuJj3fPqbyBAS8AC9FevaZ7yBeKttq/yd40/oJV+a7obN2uGT3HazZntfTZZK2CU+RlHWr43jVKv6p/yMq4grzrXzbASrQzb1fXkBsF+E6f63TqO0x5lO28sij+CuzlqlR6P/RFBSMSKsK6I9SukzpeN34GysVtg0awwW6E+1ylyk2DVYLam7au/29TP8FWE4EdLK0d6JW0FcB3zrA1wRiukzlXQnUIT/U61b89XO3/oIJ9SixaM5SGt8UFnuAwDro+zj9Wds/0f3EgyI8BkQICUNky20oYETnVObXr1nGPfZCuV5Oydbz/1/6bpzlWUcm6WrzQv3ZHtiiPTnWsJ4M07X8RWN2yLYJpVbX9I6cWeB8m1Ve1AL4M/eplsJXKY6wIJHW2vd/o522Y/znjeipkFygNGW8kZMWWB2Nfwn5DC+E9YydT3iofl1AOwWMzqJkI9yo2KxWLbrBZYHY9yA2M7/16Rpkgw5VVfbkGXA7DzcmUUDy6NMfmrqxKRZknG1lPvqepuKQFJOEirEtdUlblzdbikVR6a52uEWv5F1M/kjwNWxOTBdf8IvBgWqUpUcn7Vub7QaZbUn7VdR9KckGJBfLIFCclSQjGrEojdyqSiOBRzVe0f1vnhvL4bLlwOx6+zbF+o4jlDKwQjQd3gBPkZEGgyINBPb3tU+6mPJr1jXxdWDcHJZlX6jtOFwljjRSQaQnD0yCUVFOOSzCgXUAeBBQrDakmB1WKGJiVWSwo0i+1GD3LDZ7+xg1U1kPy0OQaTN6xX6SqtO4v5fgG4YfbDmD/Txr53NCUAhrSPlT0c3vGjl5KIq+aU1KNkFAywleiT07IKBXXXUEp/AVlxRReGAJ3eEdge0u9VN8DGlLSaqYq6U2il35IhQRkeM9iSUB7DL6cFxjH+f6CwLgZfXqyJfepvQWpuNuAR012GJ+rSR6rj1sL4Ga3V95N8//zHugzltRO4mqcy9gWVV+faJm7C81dn3PGyMUFl8GeLV+BKOs2LJzM+c+YMSpQogdOnT6N48eLuTg4RZZNksxUxCcm4eiMFV24k42p8su3xRjKuxNsfU2yPqc9LwHY3CfjB/kaEBJgQEmBM3TciOMCk9vOmngszWRDiB4SYrDDpddDrNBh1Ggxqg3qUIKz2pRyqswIBIUCewtBLVa9mQcDVQ+rnrIWqQi/VwTodTDHHYEi8YquNkRrr1DKtvazruGF0vrkLLgwUr+34Hay7f1M3bynl2sNsCIBFipZnNkN/cT+scvNmtapNbjrkJk6zH6c+J4+yJQQUwenSjzlKqw/sHw9DShwOlOqOWL+C6kYr4tJfKH1lHQx6+Z2lelvyUPoj2I6lFGx/Tn4/2dcHF4K+5Xtpmb5yJHD9DNDgZaBQxdSovBbYIc1O9htk3LwfUsQ2v7wLYxEDLhHlCtKmlxaYU9ICs3PAVo9pgTpZ2hJSm3mD/SQwpgZIf1uQlP0Q2U8Novbn1Tm1bwuk6lyA0VZyZqc1n3Mmk7GIVcpElCtIE0fR0EC1ZYaUNW4k26q38/gZVcmRKCcx4BKRT5KSqJROiVyFUzsSERG5gFff3kkDvTh7NovDAYiIiLKJPQbZY1KuDLjnz59Xj/XqpQ6KJyIicmNMKlkyddhebuulbDabsX37dhQuLF3l7692PDY2FpUqVcK+ffsQEmKbFIBuj/mVNcyvrGOeZQ3zy335JSVbCbY1a9aE0WjMnQE3O12/fh2hoaG4du0a8ua1za5Ct8f8yhrmV9Yxz7KG+eX5+cVOU0RERC7AgEtEROQCDLip/P39MWzYMPVId8f8yhrmV9Yxz7KG+eX5+cU2XCIiIhdgCZeIiMgFGHCJiIhcgAGXiIjIBRhwU40bNw6lS5dGQEAA6tevj82bN7s7SR5pzZo16NixIyIiItTk73PnznV3kjzayJEjUbduXTWwvlChQujcuTMOHjzo7mR5rPHjx6NatWpqXKRsDRo0wKJFi9ydLK8xatQo9Xf52muvuTspHmv48OEqj5y3ChUquOS9GXAB/PzzzxgwYIDqsbZt2zZUr14dbdq0wYULF9ydNI9z48YNlT9yg0J3t3r1avTr1w8bN27EsmXLkJKSgtatW6t8pJvJWqISNLZu3YotW7bg4YcfRqdOnbB37153J83j/f3335gwYYK6YaE7q1y5spr/2L6tW7cOLiG9lH1dvXr1tH79+jmOLRaLFhERoY0cOdKt6fJ08vGZM2eOu5PhVS5cuKDybfXq1e5OitcIDw/XJk+e7O5keLTY2FitXLly2rJly7SmTZtq/fv3d3eSPNawYcO06tWru+W9fb6Em5ycrO6mW7Zs6Tgn8zLL8YYNG9yaNsp9ZBo5kS9fPncnxeNZLBbMnDlT1QZI1TLdntSidOjQId33GN3e4cOHVbNYZGQkunfvjlOnTsEVvHq1oOxw6dIl9YctCyA4k+MDBw64LV2U+8gE59K21rBhQ1SpUsXdyfFYu3fvVgE2MTERwcHBmDNnjppknm5NbkqkKUyqlOnupI/OtGnTEBUVpaqTR4wYgcaNG2PPnj05vuiDzwdcIleWQuSP2mXtRV5Kvgh37NihagN+/fVXREdHq7ZwBt2bnT59Gv3791f9A6TDJ91du3btHPvS3i0BuFSpUvjll1/Qq1cv5CSfD7gFChSAwWBwrK1rJ8dFihRxW7ood3n55Zcxf/581ctbOgbR7fn5+aFs2bJqv3bt2qrk9sUXX6gOQZSeNIdJ585atWo5zkmNnXzOvv76ayQlJanvN7q9sLAwlC9fHkeOHEFO8/k2XPnjlj/q5cuXp6v6k2O2G9H9kr5lEmylWnTFihUoU6aMu5PkdeTvUQIH3axFixaqCl5qBOxbnTp1VLuk7DPY3l1cXByOHj2KokWLIqf5fAlXyJAgqbaSD2q9evUwduxY1VGjZ8+e7k6aR344ne8Ejx8/rv6wpRNQyZIl3Zo2T61Gnj59On7//XfVPnTu3Dl1XtbhDAwMdHfyPM6QIUNUlZ98lmSBcMm7VatWYcmSJe5OmkeSz1TG/gB58uRB/vz52U/gNgYNGqTmEpBq5H///VcNB5Ubk6effho5jQEXwJNPPomLFy9i6NCh6guxRo0aWLx48U0dqQhqbGTz5s3T3awIuWGRjgh080QOolmzZunOT506Fc8995ybUuW5pHr02WefVZ1Z5KZE2tgk2LZq1crdSaNc4syZMyq4Xr58GQULFkSjRo3UOHnZz2lcLYiIiMgFfL4Nl4iIyBUYcImIiFyAAZeIiMgFGHCJiIhcgAGXiIjIBRhwiYiIXIABl4iIyAUYcImIiFyAAZeIMkWn02Hu3LnuTgaR12LAJfICMg2kBLyMW9u2bd2dNCLKJM6lTOQlJLjKHMzO/P393ZYeIsoalnCJvIQEV1mj2XkLDw9Xz0lpVxZKkJV2ZBWiyMhItXi7M1nG7eGHH1bPy2oyvXv3Vqs/OZsyZQoqV66s3kuWK5OlBZ1dunQJXbp0QVBQEMqVK4d58+Y5nrt69apaFk4mgZf3kOcz3iAQ+TIGXKJc4r333kPXrl2xc+dOFfieeuop7N+/Xz0ny022adNGBWhZ0H3WrFn4888/0wVUCdiynKAEYgnOEkztC8HbjRgxAt26dcOuXbvQvn179T5XrlxxvP++ffuwaNEi9b5yvQIFCrg4F4g8mKwWRESeLTo6WjMYDFqePHnSbR9++KF6Xv6UX3rppXQ/U79+fa1Pnz5qf+LEiVp4eLgWFxfneH7BggWaXq/Xzp07p44jIiK0d95557ZpkPd49913HcdyLTm3aNEiddyxY0etZ8+e2fybE+UebMMl8hKyDrF9fV27fPnyOfYbNGiQ7jk53rFjh9qXEmf16tXV4uR2DRs2hNVqxcGDB1WVtCzG3aJFizumQdantZNr5c2bV61hK/r06aNK2Nu2bUPr1q3RuXNnPPTQQ/f5WxPlHgy4RF5CAlzGKt7sIm2umWEymdIdS6CWoC2k/fjkyZNYuHAhli1bpoK3VFF/9tlnOZJmIm/DNlyiXGLjxo03HVesWFHty6O07Upbrt369euh1+sRFRWFkJAQlC5dGsuXL7+vNEiHqejoaPz4448YO3YsJk6ceF/XI8pNWMIl8hJJSUk4d+5cunNGo9HRMUk6QtWpUweNGjXCTz/9hM2bN+O7775Tz0nnpmHDhqlgOHz4cFy8eBGvvPIKevTogcKFC6vXyPmXXnoJhQoVUqXV2NhYFZTldZkxdOhQ1K5dW/VylrTOnz/fEfCJiAGXyGssXrxYDdVxJqXTAwcOOHoQz5w5E3379lWvmzFjBipVqqSek2E8S5YsQf/+/VG3bl11LO2to0ePdlxLgnFiYiLGjBmDQYMGqUD++OOPZzp9fn5+GDJkCE6cOKGqqBs3bqzSQ0Q2Ouk5lbpPRF5K2lLnzJmjOioRkWdiGy4REZELMOASERG5ANtwiXIBtgwReT6WcImIiFyAAZeIiMgFGHCJiIhcgAGXiIjIBRhwiYiIXIABl4iIyAUYcImIiFyAAZeIiMgFGHCJiIiQ8/4frvyCsQRcb3kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 79.33%\n",
      "Validation accuracy: 74.50%\n",
      "Test accuracy: 80.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 使用LLM作为垃圾消息分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 垃圾邮件分类器\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    # 编码输入文本\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 根据pos_emb，确定模型支持的上下文长度\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # 截断\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    # 填充\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # 转换为tensor\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "    # 预估\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
