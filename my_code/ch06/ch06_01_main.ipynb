{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:33.174220Z",
     "start_time": "2025-05-18T04:39:15.106703Z"
    }
   },
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch06\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\project\\LLMs-from-scratch-CN\\ch06\\01_main-chapter-code\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:33.200545Z",
     "start_time": "2025-05-18T04:39:33.183227Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # 用于加载OpenAI的预训练权重的TensorFlow库\n",
    "        \"pandas\"      # 用于加载数据集的库\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "#查看版本号Ω"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.1.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0+cu126\n",
      "tensorflow version: 2.19.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:33.224246Z",
     "start_time": "2025-05-18T04:39:33.219555Z"
    }
   },
   "source": [
    "# 防止某些单元格执行两次\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "executed_cells = set()\n",
    "#使用一个 set 数据结构来存储已经执行过的单元格标识符\n",
    "@register_line_cell_magic\n",
    "#注册了一个名为 run_once 的魔法命令\n",
    "def run_once(line, cell):\n",
    "    if line not in executed_cells:\n",
    "        get_ipython().run_cell(cell)\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:33.852279Z",
     "start_time": "2025-05-18T04:39:33.846277Z"
    }
   },
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "# 下载数据\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "    \n",
    "    # 下载文件\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    \n",
    "    # 解压文件\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    \n",
    "    # 添加.tsv扩展名\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.516831Z",
     "start_time": "2025-05-18T04:39:33.859288Z"
    }
   },
   "source": [
    "# 数据加载\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.548640Z",
     "start_time": "2025-05-18T04:39:35.532841Z"
    }
   },
   "source": [
    "df[\"Label\"].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.586821Z",
     "start_time": "2025-05-18T04:39:35.576109Z"
    }
   },
   "source": [
    "%%run_once balance_df\n",
    "\n",
    "# 平衡正负样本\n",
    "def create_balanced_dataset(df):\n",
    "    # 下采样，以使正负样本数量相等\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.657521Z",
     "start_time": "2025-05-18T04:39:35.650766Z"
    }
   },
   "source": [
    "%%run_once label_mapping\n",
    "\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.760475Z",
     "start_time": "2025-05-18T04:39:35.753379Z"
    }
   },
   "source": [
    "balanced_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:35.970558Z",
     "start_time": "2025-05-18T04:39:35.942585Z"
    }
   },
   "source": [
    "# 数据集划分\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 根据给定的比例，计算划分索引\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # 划分数据集\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:36.821145Z",
     "start_time": "2025-05-18T04:39:36.096843Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "\n",
    "# 创建分词器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:36.857006Z",
     "start_time": "2025-05-18T04:39:36.849232Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 创建数据集\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # 编码输入数据\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        # 最大长度截断\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encode_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        # 填充\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:36.933038Z",
     "start_time": "2025-05-18T04:39:36.900015Z"
    }
   },
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:36.969395Z",
     "start_time": "2025-05-18T04:39:36.949015Z"
    }
   },
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:37.030603Z",
     "start_time": "2025-05-18T04:39:36.982859Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:37.889639Z",
     "start_time": "2025-05-18T04:39:37.044149Z"
    }
   },
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:38.049822Z",
     "start_time": "2025-05-18T04:39:38.041527Z"
    }
   },
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:39:38.088029Z",
     "start_time": "2025-05-18T04:39:38.082522Z"
    }
   },
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # qkv向量是否使用Bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# 上下文长度应小于max_length\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:21.105046Z",
     "start_time": "2025-05-18T04:39:38.096037Z"
    }
   },
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "# 下载预训练模型权重\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:23.338725Z",
     "start_time": "2025-05-18T04:40:21.146113Z"
    }
   },
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.020990Z",
     "start_time": "2025-05-18T04:40:23.356796Z"
    }
   },
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 添加分类头"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.042897Z",
     "start_time": "2025-05-18T04:40:25.037580Z"
    }
   },
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.091154Z",
     "start_time": "2025-05-18T04:40:25.087653Z"
    }
   },
   "source": [
    "# 冻结参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.577734Z",
     "start_time": "2025-05-18T04:40:25.570965Z"
    }
   },
   "source": [
    "# 替换输出层，用于分类\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.590548Z",
     "start_time": "2025-05-18T04:40:25.582775Z"
    }
   },
   "source": [
    "# 除了输出层外，令trf的最后一个模块和final_norm的参数可训练\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.618118Z",
     "start_time": "2025-05-18T04:40:25.613340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after: 7,090,946\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.672399Z",
     "start_time": "2025-05-18T04:40:25.665074Z"
    }
   },
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.718451Z",
     "start_time": "2025-05-18T04:40:25.707406Z"
    }
   },
   "source": [
    "for token_id in inputs[0].tolist():\n",
    "    word = tokenizer.decode([token_id])\n",
    "    print(f\"'{word}'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Do'\n",
      "' you'\n",
      "' have'\n",
      "' time'\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.846314Z",
     "start_time": "2025-05-18T04:40:25.753485Z"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "# (batch_size, seq_len, num_classes)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.960229Z",
     "start_time": "2025-05-18T04:40:25.950824Z"
    }
   },
   "source": [
    "# 最后一个输出，包含有最完整的信息\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:25.999138Z",
     "start_time": "2025-05-18T04:40:25.981235Z"
    }
   },
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:26.060074Z",
     "start_time": "2025-05-18T04:40:26.053928Z"
    }
   },
   "source": [
    "# 若只想要分类结果，则可以跳过softmax操作\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:26.082872Z",
     "start_time": "2025-05-18T04:40:26.077081Z"
    }
   },
   "source": [
    "# 计算分类准备率\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # 将数据移到指定设备\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            # 模型预估\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            # 获取分类结果\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            # 统计总样本量、分类正确样本量\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:32.570935Z",
     "start_time": "2025-05-18T04:40:26.108439Z"
    }
   },
   "source": [
    "# 计算不同数据集上的准确率\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:33.644142Z",
     "start_time": "2025-05-18T04:40:33.641309Z"
    }
   },
   "source": [
    "# 定义batch训练损失\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    # 只关注最后一个输出\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    # 交叉熵损失\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:33.657144Z",
     "start_time": "2025-05-18T04:40:33.651152Z"
    }
   },
   "source": [
    "# 定义loader训练损失\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:35.104597Z",
     "start_time": "2025-05-18T04:40:33.703006Z"
    }
   },
   "source": [
    "# 查看训练前，各数据集上的损失表现\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 在有监督数据上微调模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:35.157184Z",
     "start_time": "2025-05-18T04:40:35.151953Z"
    }
   },
   "source": [
    "# 定义训练过程\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 初始化梯度\n",
    "            optimizer.zero_grad()\n",
    "            # loss计算\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 权重更新\n",
    "            optimizer.step()\n",
    "            \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}) \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy * 100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:40:35.206760Z",
     "start_time": "2025-05-18T04:40:35.203348Z"
    }
   },
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:02.458533Z",
     "start_time": "2025-05-18T04:40:35.255086Z"
    }
   },
   "source": [
    "# 训练模型\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000) Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050) Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100) Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150) Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200) Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250) Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300) Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350) Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400) Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450) Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500) Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550) Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600) Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 1.45 minutes.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:02.569567Z",
     "start_time": "2025-05-18T04:42:02.565680Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 2))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:05.379611Z",
     "start_time": "2025-05-18T04:42:02.666979Z"
    }
   },
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x200 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:20.827865Z",
     "start_time": "2025-05-18T04:42:05.385619Z"
    }
   },
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 使用LLM作为垃圾消息分类器"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:20.897737Z",
     "start_time": "2025-05-18T04:42:20.893590Z"
    }
   },
   "source": [
    "# 垃圾邮件分类器\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    # 编码输入文本\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 根据pos_emb，确定模型支持的上下文长度\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # 截断\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    # 填充\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # 转换为tensor\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "    # 预估\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:21.013033Z",
     "start_time": "2025-05-18T04:42:20.992858Z"
    }
   },
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:24.489824Z",
     "start_time": "2025-05-18T04:42:21.073230Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:27.694215Z",
     "start_time": "2025-05-18T04:42:24.495831Z"
    }
   },
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T04:42:31.492671Z",
     "start_time": "2025-05-18T04:42:31.490453Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
