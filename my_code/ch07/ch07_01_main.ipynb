{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch07/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch07\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # 绘图库\n",
    "    \"tiktoken\",    # 分词器\n",
    "    \"torch\",       # 深度学习库\n",
    "    \"tqdm\",        # 进度条\n",
    "    \"tensorflow\",  # 用于加载OpenAI的预训练权重\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "# 读取并输出版本号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 为有监督微调准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    # else:\n",
    "    #     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #         text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "# 查看指令样本\n",
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 处理Input为空/非空的情况\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input非空\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input为空\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "# 0.85、0.1、0.05\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 构建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 拼接指令\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # 拼接输出text\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            # 合并指令+输出\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            # 编码上述信息\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 使用gpt2的bpe编码器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充方法\n",
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_fn(\n",
    "        batch, \n",
    "        pad_token_id=50256, \n",
    "        ignore_index=-100,\n",
    "        allowed_max_length=None,\n",
    "        device=\"cpu\"\n",
    "):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # targets中仅保留一个<|endoftext|>，其余填充为ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # 最大长度截断\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# 计算loss时，忽略tokenid = -100的样本\n",
    "logits_3 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_3, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 创建指令数据集的数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# 将部分参数提前填充，并生成一个新的函数，以适配collate函数的要求\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 加载预训练的大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 29.3kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 655kiB/s] \n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 37.3kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [53:21<00:00, 443kiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 3.19MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 484kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 298kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# 查看验证集数据\n",
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "# 提取response\n",
    "response_text = (\n",
    "    # 去除输入文本\n",
    "    generated_text[len(input_text):]\n",
    "    # 去除无意义的输出\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 在指令数据上微调大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259105682373047\n",
      "Validation loss: 3.7619349479675295\n"
     ]
    }
   ],
   "source": [
    "# 查看训练前的loss\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.800, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.535, Val loss 0.732\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.737\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.731\n",
      "Ep 1 (Step 000085): Train loss 0.513, Val loss 0.715\n",
      "Ep 1 (Step 000090): Train loss 0.571, Val loss 0.696\n",
      "Ep 1 (Step 000095): Train loss 0.504, Val loss 0.687\n",
      "Ep 1 (Step 000100): Train loss 0.507, Val loss 0.682\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.674\n",
      "Ep 1 (Step 000110): Train loss 0.562, Val loss 0.669\n",
      "Ep 1 (Step 000115): Train loss 0.519, Val loss 0.665\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.437, Val loss 0.670\n",
      "Ep 2 (Step 000125): Train loss 0.454, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.681\n",
      "Ep 2 (Step 000135): Train loss 0.406, Val loss 0.677\n",
      "Ep 2 (Step 000140): Train loss 0.407, Val loss 0.676\n",
      "Ep 2 (Step 000145): Train loss 0.374, Val loss 0.677\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.674\n",
      "Ep 2 (Step 000155): Train loss 0.419, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.414, Val loss 0.685\n",
      "Ep 2 (Step 000165): Train loss 0.380, Val loss 0.687\n",
      "Ep 2 (Step 000170): Train loss 0.327, Val loss 0.679\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.668\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.416, Val loss 0.658\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.649\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.634\n",
      "Ep 2 (Step 000200): Train loss 0.311, Val loss 0.632\n",
      "Ep 2 (Step 000205): Train loss 0.355, Val loss 0.627\n",
      "Ep 2 (Step 000210): Train loss 0.365, Val loss 0.629\n",
      "Ep 2 (Step 000215): Train loss 0.394, Val loss 0.637\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.653\n",
      "Ep 2 (Step 000225): Train loss 0.351, Val loss 0.667\n",
      "Ep 2 (Step 000230): Train loss 0.297, Val loss 0.655\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 52.29 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失曲线\n",
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 抽取并保存模型回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> sult is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> er hour.\n",
      "\n",
      "### Result:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is:\n",
      "\n",
      "The result is\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    # 输入格式化\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 生成回答\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    geneerated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    # 提取有效回答\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比output\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [02:33<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# 保存测试集的结果\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 评价微调后的大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# 检测ollama是否正在运行\n",
    "import psutil \n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Lanunch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载测试数据\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "# 我们的初始数据集\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "# 通过REST api访问ollama\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # 构造请求数据\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0.,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # dict转化json并编码\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # 解析返回结果\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> A simple one!\n",
      "\n",
      "Model response: \"The author of 'Pride and Prejudice' is Jane Austen.\"\n",
      "\n",
      "Score: 100\n",
      "\n",
      "Why? Because the model response accurately answers the question by naming the correct author of the novel \"Pride and Prejudice\", which is indeed Jane Austen. The response matches the instruction perfectly, making it a perfect score!\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 使用llama3对模型结果进行打分0-100\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct out `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDataset response:\")\n",
    "print(\">>\", entry['output'])\n",
    "print(\"\\nModel response:\")\n",
    "print(\">>\", entry[\"model_response\"])\n",
    "print(\"\\nScore:\")\n",
    "print(\">>\", query_model(prompt))\n",
    "print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [01:15<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 47.79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 封装上述功能\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85,\n",
       " 40,\n",
       " 98,\n",
       " 60,\n",
       " 60,\n",
       " 0,\n",
       " 20,\n",
       " 100,\n",
       " 20,\n",
       " 40,\n",
       " 95,\n",
       " 100,\n",
       " 20,\n",
       " 95,\n",
       " 20,\n",
       " 40,\n",
       " 95,\n",
       " 80,\n",
       " 85,\n",
       " 67,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 60,\n",
       " 80,\n",
       " 40,\n",
       " 95,\n",
       " 20,\n",
       " 98,\n",
       " 80,\n",
       " 40,\n",
       " 44,\n",
       " 98,\n",
       " 20,\n",
       " 100,\n",
       " 95,\n",
       " 100,\n",
       " 20,\n",
       " 85,\n",
       " 100,\n",
       " 20,\n",
       " 60,\n",
       " 60,\n",
       " 92,\n",
       " 20,\n",
       " 4,\n",
       " 95,\n",
       " 67,\n",
       " 40,\n",
       " 90,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 0,\n",
       " 85,\n",
       " 80,\n",
       " 95,\n",
       " 20,\n",
       " 20,\n",
       " 5,\n",
       " 60,\n",
       " 40,\n",
       " 60,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 90,\n",
       " 0,\n",
       " 20,\n",
       " 20,\n",
       " 92,\n",
       " 20,\n",
       " 100,\n",
       " 95,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 40,\n",
       " 20,\n",
       " 20,\n",
       " 85,\n",
       " 66,\n",
       " 20,\n",
       " 20,\n",
       " 0,\n",
       " 40,\n",
       " 95,\n",
       " 4,\n",
       " 85,\n",
       " 85,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
