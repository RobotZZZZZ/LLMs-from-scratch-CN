{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 7.1 CHANGING PROMPT STYLES\n",
    "After finetuning the model with the Alpaca prompt style, try the Phi-3 prompt style\n",
    "shown in figure 7.4 and observe if it affects the response quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch07/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch07\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"<|user|>\"\n",
    "        f\"\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 处理Input为空/非空的情况\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 拼接指令\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # 拼接输出text\n",
    "            response_text = f\"\\n\\n<|assistant|>\\n{entry['output']}\"\n",
    "            # 合并指令+输出\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            # 编码上述信息\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_fn(\n",
    "        batch, \n",
    "        pad_token_id=50256, \n",
    "        ignore_index=-100,\n",
    "        allowed_max_length=None,\n",
    "        device=\"cpu\"\n",
    "):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # targets中仅保留一个<|endoftext|>，其余填充为ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # 最大长度截断\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# 将部分参数提前填充，并生成一个新的函数，以适配collate函数的要求\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 使用gpt2的bpe编码器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    # else:\n",
    "    #     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #         text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "# 0.85、0.1、0.05\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "<|assistant|>\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input为空\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n<|assistant|>\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.748, Val loss 2.757\n",
      "Ep 1 (Step 000005): Train loss 1.676, Val loss 1.503\n",
      "Ep 1 (Step 000010): Train loss 1.170, Val loss 1.262\n",
      "Ep 1 (Step 000015): Train loss 1.168, Val loss 1.207\n",
      "Ep 1 (Step 000020): Train loss 1.062, Val loss 1.182\n",
      "Ep 1 (Step 000025): Train loss 1.028, Val loss 1.143\n",
      "Ep 1 (Step 000030): Train loss 1.084, Val loss 1.112\n",
      "Ep 1 (Step 000035): Train loss 0.953, Val loss 1.070\n",
      "Ep 1 (Step 000040): Train loss 0.909, Val loss 1.072\n",
      "Ep 1 (Step 000045): Train loss 0.855, Val loss 1.053\n",
      "Ep 1 (Step 000050): Train loss 0.899, Val loss 1.038\n",
      "Ep 1 (Step 000055): Train loss 1.006, Val loss 1.014\n",
      "Ep 1 (Step 000060): Train loss 0.957, Val loss 0.991\n",
      "Ep 1 (Step 000065): Train loss 0.876, Val loss 0.981\n",
      "Ep 1 (Step 000070): Train loss 0.750, Val loss 0.983\n",
      "Ep 1 (Step 000075): Train loss 0.792, Val loss 0.994\n",
      "Ep 1 (Step 000080): Train loss 0.797, Val loss 0.974\n",
      "Ep 1 (Step 000085): Train loss 0.677, Val loss 0.949\n",
      "Ep 1 (Step 000090): Train loss 0.737, Val loss 0.924\n",
      "Ep 1 (Step 000095): Train loss 0.694, Val loss 0.920\n",
      "Ep 1 (Step 000100): Train loss 0.680, Val loss 0.916\n",
      "Ep 1 (Step 000105): Train loss 0.745, Val loss 0.910\n",
      "Ep 1 (Step 000110): Train loss 0.736, Val loss 0.900\n",
      "Ep 1 (Step 000115): Train loss 0.681, Val loss 0.892\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The active sentence is 'The chef cooks the meal every day.'<|endoftext|>The following is a list of the most commonly used words in the English language.  1. The  2. The \n",
      "Ep 2 (Step 000120): Train loss 0.584, Val loss 0.897\n",
      "Ep 2 (Step 000125): Train loss 0.600, Val loss 0.923\n",
      "Ep 2 (Step 000130): Train loss 0.601, Val loss 0.921\n",
      "Ep 2 (Step 000135): Train loss 0.545, Val loss 0.936\n",
      "Ep 2 (Step 000140): Train loss 0.552, Val loss 0.918\n",
      "Ep 2 (Step 000145): Train loss 0.494, Val loss 0.912\n",
      "Ep 2 (Step 000150): Train loss 0.511, Val loss 0.912\n",
      "Ep 2 (Step 000155): Train loss 0.559, Val loss 0.910\n",
      "Ep 2 (Step 000160): Train loss 0.545, Val loss 0.914\n",
      "Ep 2 (Step 000165): Train loss 0.500, Val loss 0.918\n",
      "Ep 2 (Step 000170): Train loss 0.441, Val loss 0.925\n",
      "Ep 2 (Step 000175): Train loss 0.458, Val loss 0.918\n",
      "Ep 2 (Step 000180): Train loss 0.521, Val loss 0.891\n",
      "Ep 2 (Step 000185): Train loss 0.561, Val loss 0.891\n",
      "Ep 2 (Step 000190): Train loss 0.465, Val loss 0.878\n",
      "Ep 2 (Step 000195): Train loss 0.440, Val loss 0.860\n",
      "Ep 2 (Step 000200): Train loss 0.420, Val loss 0.861\n",
      "Ep 2 (Step 000205): Train loss 0.472, Val loss 0.850\n",
      "Ep 2 (Step 000210): Train loss 0.478, Val loss 0.853\n",
      "Ep 2 (Step 000215): Train loss 0.525, Val loss 0.861\n",
      "Ep 2 (Step 000220): Train loss 0.395, Val loss 0.875\n",
      "Ep 2 (Step 000225): Train loss 0.445, Val loss 0.899\n",
      "Ep 2 (Step 000230): Train loss 0.396, Val loss 0.880\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The meal is cooked every day by the chef.<|endoftext|>The following is a list of all the animals that are classified as reptiles.  ### Input: Snake  <|assistant|>\n",
      "Training completed in 2.66 minutes.\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失曲线\n",
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "<|user|>\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is cumulus.\n",
      "-------------------------------------\n",
      "<|user|>\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    # 输入格式化\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 生成回答\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    # 提取有效回答\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比output\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [02:33<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# 保存测试集的结果\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response-phi3.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-phi3-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-phi3-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = GPTModel(BASE_CONFIG)\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))\n",
    "# model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# 检测ollama是否正在运行\n",
    "# 运行ollama: ollama run llama3\n",
    "import psutil \n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Lanunch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "# 通过REST api访问ollama\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # 构造请求数据\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0.,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # dict转化json并编码\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # 解析返回结果\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "model_name = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model_name)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  36%|███▋      | 40/110 [00:16<00:35,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: A sonnet is a 14-line poem with a specific rhyme scheme and meter, often written in iambic pentameter.\n",
      "\n",
      "Score: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  42%|████▏     | 46/110 [00:18<00:25,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: I'd rate this model's response as **80**.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  45%|████▌     | 50/110 [00:19<00:22,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Commence\n",
      "Score: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  75%|███████▌  | 83/110 [00:32<00:23,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: I'd be happy to help!\n",
      "\n",
      "For the translation task, I would give myself a score of 100 because my response matches the correct Italian translation: \"Dove posso comprare i biglietti?\"\n",
      "\n",
      "As for the capital of Italy question, I would also give myself a score of 100 because my response is accurate and matches the correct answer: \"The capital of Italy is Rome.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:42<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 106 of 110\n",
      "Average score: 54.17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 封装上述功能\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85,\n",
       " 20,\n",
       " 98,\n",
       " 40,\n",
       " 95,\n",
       " 20,\n",
       " 10,\n",
       " 80,\n",
       " 20,\n",
       " 60,\n",
       " 95,\n",
       " 95,\n",
       " 20,\n",
       " 95,\n",
       " 0,\n",
       " 20,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 75,\n",
       " 20,\n",
       " 60,\n",
       " 40,\n",
       " 80,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 14,\n",
       " 95,\n",
       " 80,\n",
       " 95,\n",
       " 80,\n",
       " 92,\n",
       " 80,\n",
       " 95,\n",
       " 20,\n",
       " 100,\n",
       " 95,\n",
       " 20,\n",
       " 67,\n",
       " 90,\n",
       " 92,\n",
       " 50,\n",
       " 67,\n",
       " 20,\n",
       " 92,\n",
       " 95,\n",
       " 60,\n",
       " 95,\n",
       " 4,\n",
       " 4,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 50,\n",
       " 60,\n",
       " 80,\n",
       " 95,\n",
       " 60,\n",
       " 20,\n",
       " 4,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 67,\n",
       " 40,\n",
       " 20,\n",
       " 95,\n",
       " 67,\n",
       " 20,\n",
       " 95,\n",
       " 25,\n",
       " 95,\n",
       " 60,\n",
       " 95,\n",
       " 20,\n",
       " 100,\n",
       " 80,\n",
       " 95,\n",
       " 80,\n",
       " 60,\n",
       " 85,\n",
       " 82,\n",
       " 0,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 40,\n",
       " 20,\n",
       " 80,\n",
       " 40,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 67,\n",
       " 67,\n",
       " 20,\n",
       " 20,\n",
       " 95,\n",
       " 4,\n",
       " 20,\n",
       " 4,\n",
       " 85,\n",
       " 20,\n",
       " 40]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 7.2 INSTRUCTION AND INPUT MASKING\n",
    "After completing the chapter and finetuning the model with the InstructionDataset\n",
    "implemented in this section, replace the instruction and input tokens with the -100\n",
    "mask to implement the instruction masking method illustrated in Figure 7.13. Then,\n",
    "evaluate whether this has a positive effect on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要的思路是：在计算loss时，进行mask\n",
    "# 这里的loss计算，主要是使用torch.nn.functional.cross_entropy(logits, labels)\n",
    "# 将需要mask的token对应的label设置为-100，然后计算loss就能实现mask的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch07/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch07\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    # else:\n",
    "    #     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #         text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "# 0.85、0.1、0.05\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 处理Input为空/非空的情况\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input非空\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model_mask = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model_mask, params)\n",
    "model_mask.to(device)\n",
    "model_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset_mask(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 拼接指令\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # 拼接输出text\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            # 合并指令+输出\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            # 编码上述信息\n",
    "            self.encoded_texts.append(\n",
    "                {\n",
    "                    \"text\": tokenizer.encode(full_text),\n",
    "                    \"prefix_len\": len(tokenizer.encode(instruction_plus_input))\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_fn_mask(\n",
    "        batch, \n",
    "        pad_token_id=50256, \n",
    "        ignore_index=-100,\n",
    "        allowed_max_length=None,\n",
    "        device=\"cpu\",\n",
    "        ignore_prompt_tokens=False\n",
    "):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    if ignore_prompt_tokens:\n",
    "        batch_max_length = max(len(items[\"text\"])+1 for items in batch)\n",
    "    else:\n",
    "        batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for items in batch:\n",
    "        prefix_len = 0\n",
    "        if ignore_prompt_tokens:\n",
    "            item = items[\"text\"]\n",
    "            prefix_len = items[\"prefix_len\"]\n",
    "        else:\n",
    "            item = items\n",
    "\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # 将指令和输入的token设置为ignore_index\n",
    "        if ignore_prompt_tokens:\n",
    "            # 考虑targets右移了一位，故需要-1\n",
    "            targets[:prefix_len-1] = ignore_index\n",
    "\n",
    "        # targets中仅保留一个<|endoftext|>，其余填充为ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # 最大长度截断\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# 将部分参数提前填充，并生成一个新的函数，以适配collate函数的要求\n",
    "customized_collate_fn_mask = partial(\n",
    "    custom_collate_fn_mask,\n",
    "    device=device,\n",
    "    allowed_max_length=1024,\n",
    "    ignore_prompt_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 使用gpt2的bpe编码器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset_mask = InstructionDataset_mask(train_data, tokenizer)\n",
    "train_loader_mask = DataLoader(\n",
    "    train_dataset_mask,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn_mask,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset_mask = InstructionDataset_mask(val_data, tokenizer)\n",
    "val_loader_mask = DataLoader(\n",
    "    val_dataset_mask,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn_mask,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset_mask = InstructionDataset_mask(test_data, tokenizer)\n",
    "test_loader_mask = DataLoader(\n",
    "    test_dataset_mask,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn_mask,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "# 校验数据\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader_mask:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  5931, 10451,   329,\n",
      "        21072,  6588,   378,    30,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5931, 10451,   329, 21072,  6588,   378,   318, 11013,    17,\n",
      "         8220,    18,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='mps:0')\n",
      "\n",
      "\n",
      "Targets:\n",
      " tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         5931, 10451,   329, 21072,  6588,   378,   318, 11013,    17,  8220,\n",
      "           18,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs:\\n\", inputs[1])\n",
    "print(\"\\n\\nTargets:\\n\", targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium carbonate?\n",
      "\n",
      "### Response:\n",
      "The chemical formula for sodium carbonate is Na2CO3.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(list(inputs[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Response:\n",
      "The chemical formula for sodium carbonate is Na2CO3.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "non_masked_targets = targets[1][targets[1] != -100]\n",
    "\n",
    "print(tokenizer.decode(list(non_masked_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.3913217067718504\n",
      "Validation loss: 2.2625606298446654\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "\n",
    "# 查看训练前的loss\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader_mask, model_mask, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader_mask, model_mask, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.636, Val loss 1.620\n",
      "Ep 1 (Step 000005): Train loss 1.060, Val loss 1.026\n",
      "Ep 1 (Step 000010): Train loss 0.881, Val loss 0.939\n",
      "Ep 1 (Step 000015): Train loss 0.878, Val loss 0.903\n",
      "Ep 1 (Step 000020): Train loss 0.817, Val loss 0.879\n",
      "Ep 1 (Step 000025): Train loss 0.738, Val loss 0.847\n",
      "Ep 1 (Step 000030): Train loss 0.779, Val loss 0.825\n",
      "Ep 1 (Step 000035): Train loss 0.645, Val loss 0.806\n",
      "Ep 1 (Step 000040): Train loss 0.757, Val loss 0.804\n",
      "Ep 1 (Step 000045): Train loss 0.564, Val loss 0.802\n",
      "Ep 1 (Step 000050): Train loss 0.661, Val loss 0.789\n",
      "Ep 1 (Step 000055): Train loss 0.893, Val loss 0.785\n",
      "Ep 1 (Step 000060): Train loss 0.669, Val loss 0.773\n",
      "Ep 1 (Step 000065): Train loss 0.563, Val loss 0.759\n",
      "Ep 1 (Step 000070): Train loss 0.523, Val loss 0.758\n",
      "Ep 1 (Step 000075): Train loss 0.533, Val loss 0.751\n",
      "Ep 1 (Step 000080): Train loss 0.557, Val loss 0.742\n",
      "Ep 1 (Step 000085): Train loss 0.481, Val loss 0.736\n",
      "Ep 1 (Step 000090): Train loss 0.526, Val loss 0.725\n",
      "Ep 1 (Step 000095): Train loss 0.392, Val loss 0.717\n",
      "Ep 1 (Step 000100): Train loss 0.485, Val loss 0.696\n",
      "Ep 1 (Step 000105): Train loss 0.520, Val loss 0.698\n",
      "Ep 1 (Step 000110): Train loss 0.539, Val loss 0.692\n",
      "Ep 1 (Step 000115): Train loss 0.438, Val loss 0.686\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The U.S. government is considering a new policy to protect the privacy of U.S. citizens abroad.  The new policy would require the government to\n",
      "Ep 2 (Step 000120): Train loss 0.378, Val loss 0.687\n",
      "Ep 2 (Step 000125): Train loss 0.358, Val loss 0.694\n",
      "Ep 2 (Step 000130): Train loss 0.337, Val loss 0.711\n",
      "Ep 2 (Step 000135): Train loss 0.271, Val loss 0.723\n",
      "Ep 2 (Step 000140): Train loss 0.278, Val loss 0.739\n",
      "Ep 2 (Step 000145): Train loss 0.260, Val loss 0.736\n",
      "Ep 2 (Step 000150): Train loss 0.201, Val loss 0.736\n",
      "Ep 2 (Step 000155): Train loss 0.282, Val loss 0.756\n",
      "Ep 2 (Step 000160): Train loss 0.366, Val loss 0.760\n",
      "Ep 2 (Step 000165): Train loss 0.273, Val loss 0.748\n",
      "Ep 2 (Step 000170): Train loss 0.168, Val loss 0.739\n",
      "Ep 2 (Step 000175): Train loss 0.218, Val loss 0.729\n",
      "Ep 2 (Step 000180): Train loss 0.310, Val loss 0.713\n",
      "Ep 2 (Step 000185): Train loss 0.321, Val loss 0.718\n",
      "Ep 2 (Step 000190): Train loss 0.188, Val loss 0.716\n",
      "Ep 2 (Step 000195): Train loss 0.198, Val loss 0.707\n",
      "Ep 2 (Step 000200): Train loss 0.153, Val loss 0.703\n",
      "Ep 2 (Step 000205): Train loss 0.230, Val loss 0.696\n",
      "Ep 2 (Step 000210): Train loss 0.258, Val loss 0.693\n",
      "Ep 2 (Step 000215): Train loss 0.295, Val loss 0.684\n",
      "Ep 2 (Step 000220): Train loss 0.167, Val loss 0.692\n",
      "Ep 2 (Step 000225): Train loss 0.143, Val loss 0.698\n",
      "Ep 2 (Step 000230): Train loss 0.126, Val loss 0.702\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The new year is a time of great change and excitement. It is a time when new ideas and new ideas are born. It is a time when new ideas are\n",
      "Training completed in 3.09 minutes.\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_mask.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model_mask, train_loader_mask, val_loader_mask, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失曲线\n",
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of cloud that typically forms when a strong wind blows from the northwest or southeast, creating a thunderstorm.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    # 输入格式化\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 生成回答\n",
    "    token_ids = generate(\n",
    "        model=model_mask,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    # 提取有效回答\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比output\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [02:16<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# 保存测试集的结果\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model_mask,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response-mask.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-mask-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-mask-sft.pth\"\n",
    "torch.save(model_mask.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# 检测ollama是否正在运行\n",
    "# 运行ollama: ollama run llama3\n",
    "import psutil \n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Lanunch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "# 通过REST api访问ollama\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # 构造请求数据\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0.,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # dict转化json并编码\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # 解析返回结果\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "model_name = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model_name)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"instruction-data-with-response-mask.json\", \"r\") as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:35<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 48.58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 封装上述功能\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 7.3 FINETUNING ON THE ORIGINAL ALPACA DATASET\n",
    "The so-called Alpaca dataset by researchers at Stanford is one of the earliest and\n",
    "most popular openly shared instruction datasets, consisting of 52,002 entries. As an\n",
    "alternative to the instruction-data.json file we use in this chapter, consider\n",
    "finetuning an LLM on this dataset. The dataset is available at the following URL:\n",
    "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json\n",
    "This dataset contains 52,002 entries, which is approximately 50 times more than\n",
    "those we used in this chapter, and most entries are longer as well. Thus, it's highly\n",
    "recommended to conduct the training using a GPU to accelerate the finetuning\n",
    "process. If you encounter out-of-memory errors, consider reducing the batch_size\n",
    "from 8 to 4, 2, or even 1. Additionally, lowering the allowed_max_length from 1024\n",
    "to 512 or 256 can further help manage memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    # else:\n",
    "    #     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #         text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"alpaca_data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com\"\n",
    "    \"/tatsu-lab/stanford_alpaca/main/alpaca_data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 7.4 PARAMETER-EFFICIENT FINETUNING WITH LORA\n",
    "To instruction finetune an LLM more efficiently, modify the code in this chapter to use\n",
    "the low-rank adaptation method (LoRA) from appendix E. Compare the training\n",
    "runtime and model performance before and after the modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 构建LoRA layer\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        # A矩阵进行kaiming初始化，B矩阵进行全0初始化\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建整合了LoRALayer的线性层\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型中的所有线性层替换为LoRA层\n",
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # replace\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # 递归\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结原模型的参数\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换线性层为可训练的LoRA层\n",
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
