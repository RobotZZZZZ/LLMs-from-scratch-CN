{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch07/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch07\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # 绘图库\n",
    "    \"tiktoken\",    # 分词器\n",
    "    \"torch\",       # 深度学习库\n",
    "    \"tqdm\",        # 进度条\n",
    "    \"tensorflow\",  # 用于加载OpenAI的预训练权重\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "# 读取并输出版本号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 为有监督微调准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    # else:\n",
    "    #     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #         text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "# 查看指令样本\n",
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 处理Input为空/非空的情况\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input非空\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# 测试format效果\n",
    "# Input为空\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "# 0.85、0.1、0.05\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 构建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 拼接指令\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # 拼接输出text\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            # 合并指令+输出\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            # 编码上述信息\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 使用gpt2的bpe编码器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充方法\n",
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加输入和目标\n",
    "# 填充方法\n",
    "def custom_collate_fn(\n",
    "        batch, \n",
    "        pad_token_id=50256, \n",
    "        ignore_index=-100,\n",
    "        allowed_max_length=None,\n",
    "        device=\"cpu\"\n",
    "):\n",
    "    # 填充至当前batch的最大长度+1\n",
    "    # 至少会填充一个<|endoftext|>\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 填充endoftext\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # 去除最后一个token, 作为输入\n",
    "        # 相对的，如果去掉第一个token，则作为目标\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # targets中仅保留一个<|endoftext|>，其余填充为ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # 最大长度截断\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    # stack to batch\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# 计算loss时，忽略tokenid = -100的样本\n",
    "logits_3 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_3, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 创建指令数据集的数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# 将部分参数提前填充，并生成一个新的函数，以适配collate函数的要求\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 加载预训练的大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# 查看验证集数据\n",
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "# 提取response\n",
    "response_text = (\n",
    "    # 去除输入文本\n",
    "    generated_text[len(input_text):]\n",
    "    # 去除无意义的输出\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 在指令数据上微调大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259105682373047\n",
      "Validation loss: 3.7619349479675295\n"
     ]
    }
   ],
   "source": [
    "# 查看训练前的loss\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.800, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.535, Val loss 0.732\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.737\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.731\n",
      "Ep 1 (Step 000085): Train loss 0.513, Val loss 0.715\n",
      "Ep 1 (Step 000090): Train loss 0.571, Val loss 0.696\n",
      "Ep 1 (Step 000095): Train loss 0.504, Val loss 0.687\n",
      "Ep 1 (Step 000100): Train loss 0.507, Val loss 0.682\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.674\n",
      "Ep 1 (Step 000110): Train loss 0.562, Val loss 0.669\n",
      "Ep 1 (Step 000115): Train loss 0.519, Val loss 0.665\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.437, Val loss 0.670\n",
      "Ep 2 (Step 000125): Train loss 0.454, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.448, Val loss 0.681\n",
      "Ep 2 (Step 000135): Train loss 0.406, Val loss 0.677\n",
      "Ep 2 (Step 000140): Train loss 0.407, Val loss 0.676\n",
      "Ep 2 (Step 000145): Train loss 0.373, Val loss 0.677\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.674\n",
      "Ep 2 (Step 000155): Train loss 0.419, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.414, Val loss 0.685\n",
      "Ep 2 (Step 000165): Train loss 0.380, Val loss 0.688\n",
      "Ep 2 (Step 000170): Train loss 0.327, Val loss 0.679\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.668\n",
      "Ep 2 (Step 000180): Train loss 0.390, Val loss 0.657\n",
      "Ep 2 (Step 000185): Train loss 0.416, Val loss 0.659\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.650\n",
      "Ep 2 (Step 000195): Train loss 0.326, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.311, Val loss 0.632\n",
      "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.628\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.628\n",
      "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.635\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.346, Val loss 0.663\n",
      "Ep 2 (Step 000230): Train loss 0.299, Val loss 0.657\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked everyday by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 3.30 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失曲线\n",
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 抽取并保存模型回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    # 输入格式化\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 生成回答\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    # 提取有效回答\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比output\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:58<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# 保存测试集的结果\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 评价微调后的大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# 检测ollama是否正在运行\n",
    "import psutil \n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Lanunch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载测试数据\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "# 我们的初始数据集\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "# 通过REST api访问ollama\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # 构造请求数据\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0.,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # dict转化json并编码\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # 解析返回结果\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> A simple one!\n",
      "\n",
      "Model response: \"The author of 'Pride and Prejudice' is Jane Austen.\"\n",
      "\n",
      "Score: 100\n",
      "\n",
      "Why? Because the model response accurately answers the question by naming the correct author of the novel \"Pride and Prejudice\", which is indeed Jane Austen. The response matches the instruction perfectly, making it a perfect score!\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 使用llama3对模型结果进行打分0-100\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct out `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDataset response:\")\n",
    "print(\">>\", entry['output'])\n",
    "print(\"\\nModel response:\")\n",
    "print(\">>\", entry[\"model_response\"])\n",
    "print(\"\\nScore:\")\n",
    "print(\">>\", query_model(prompt))\n",
    "print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:34<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 49.08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 封装上述功能\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85,\n",
       " 40,\n",
       " 98,\n",
       " 60,\n",
       " 60,\n",
       " 0,\n",
       " 20,\n",
       " 100,\n",
       " 20,\n",
       " 40,\n",
       " 95,\n",
       " 100,\n",
       " 20,\n",
       " 95,\n",
       " 20,\n",
       " 20,\n",
       " 95,\n",
       " 80,\n",
       " 85,\n",
       " 67,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 60,\n",
       " 80,\n",
       " 40,\n",
       " 95,\n",
       " 20,\n",
       " 98,\n",
       " 80,\n",
       " 20,\n",
       " 44,\n",
       " 98,\n",
       " 20,\n",
       " 100,\n",
       " 95,\n",
       " 100,\n",
       " 20,\n",
       " 85,\n",
       " 100,\n",
       " 4,\n",
       " 60,\n",
       " 60,\n",
       " 92,\n",
       " 20,\n",
       " 4,\n",
       " 95,\n",
       " 80,\n",
       " 40,\n",
       " 90,\n",
       " 44,\n",
       " 60,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 0,\n",
       " 85,\n",
       " 80,\n",
       " 95,\n",
       " 20,\n",
       " 20,\n",
       " 5,\n",
       " 60,\n",
       " 40,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 90,\n",
       " 75,\n",
       " 92,\n",
       " 20,\n",
       " 92,\n",
       " 20,\n",
       " 100,\n",
       " 95,\n",
       " 100,\n",
       " 4,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 40,\n",
       " 20,\n",
       " 20,\n",
       " 85,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 0,\n",
       " 40,\n",
       " 95,\n",
       " 20,\n",
       " 85,\n",
       " 85,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
