{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.430608Z",
     "start_time": "2025-04-29T14:02:57.425695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch07/04_preference-tuning-with-dpo\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch07\", \"04_preference-tuning-with-dpo\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.548077Z",
     "start_time": "2025-04-29T14:02:57.471889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"tiktoken\",    # 分词器\n",
    "    \"torch\",       # 深度学习库\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 加载偏好数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.673432Z",
     "start_time": "2025-04-29T14:02:57.644737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data-with-preference.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/04_preference-tuning-with-dpo/instruction-data-with-preference.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.784546Z",
     "start_time": "2025-04-29T14:02:57.779153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Identify the correct spelling of the following word.',\n",
      " 'input': 'Ocassion',\n",
      " 'output': \"The correct spelling is 'Occasion.'\",\n",
      " 'rejected': \"The correct spelling is obviously 'Occasion.'\",\n",
      " 'chosen': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "# 查看测试数据\n",
    "import pprint\n",
    "\n",
    "pprint.pp(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.886767Z",
     "start_time": "2025-04-29T14:02:57.881549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"What is an antonym of 'complicated'?\",\n",
      " 'input': '',\n",
      " 'output': \"An antonym of 'complicated' is 'simple'.\",\n",
      " 'chosen': \"A suitable antonym for 'complicated' would be 'simple'.\",\n",
      " 'rejected': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:57.984678Z",
     "start_time": "2025-04-29T14:02:57.980152Z"
    }
   },
   "outputs": [],
   "source": [
    "# 格式化函数\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.081795Z",
     "start_time": "2025-04-29T14:02:58.077079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.189633Z",
     "start_time": "2025-04-29T14:02:58.185549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "desired_response = f\"### Response:\\n{data[50]['chosen']}\"\n",
    "print(desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.304409Z",
     "start_time": "2025-04-29T14:02:58.298100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is obviously 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "possible_response = f\"### Response:\\n{data[50]['rejected']}\"\n",
    "print(possible_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 划分训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.416548Z",
     "start_time": "2025-04-29T14:02:58.412159Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.590731Z",
     "start_time": "2025-04-29T14:02:58.586170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 开发`PreferenceDataset`类与批处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.725771Z",
     "start_time": "2025-04-29T14:02:58.720616Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # 文本编码\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 输入格式化\n",
    "            prompt = format_input(entry)\n",
    "            # 偏好数据\n",
    "            rejected_response = entry[\"rejected\"]\n",
    "            chosen_response = entry[\"chosen\"]\n",
    "\n",
    "            # 编码\n",
    "            prompt_tokens = tokenizer.encode(prompt)\n",
    "            # 拼接输入和偏好数据, 并编码\n",
    "            chosen_full_text = f\"{prompt}\\n\\n### Response:\\n{chosen_response}\"\n",
    "            rejected_full_text = f\"{prompt}\\n\\n### Response:\\n{rejected_response}\"\n",
    "            chosen_full_tokens = tokenizer.encode(chosen_full_text)\n",
    "            rejected_full_tokens = tokenizer.encode(rejected_full_text)\n",
    "\n",
    "            self.encoded_texts.append({\n",
    "                \"prompt\": prompt_tokens,\n",
    "                \"chosen\": chosen_full_tokens,\n",
    "                \"rejected\": rejected_full_tokens,\n",
    "            })\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.858553Z",
     "start_time": "2025-04-29T14:02:58.851884Z"
    }
   },
   "outputs": [],
   "source": [
    "# 批处理函数\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    allowed_max_length=None,\n",
    "    mask_prompt_tokens=True,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_data = {\n",
    "        \"prompt\": [],\n",
    "        \"chosen\": [],\n",
    "        \"rejected\": [],\n",
    "        \"rejected_mask\": [],\n",
    "        \"chosen_mask\": []\n",
    "    }\n",
    "\n",
    "    # 确定该批样本的最大长度+1\n",
    "    max_length_common = 0\n",
    "    if batch:\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            current_max = max(len(item[key])+1 for item in batch)\n",
    "            max_length_common = max(max_length_common, current_max)\n",
    "    \n",
    "    # 填充+mask无效信息(提示词+填充词)\n",
    "    for item in batch:\n",
    "        prompt = torch.tensor(item[\"prompt\"])\n",
    "        batch_data[\"prompt\"].append(prompt)\n",
    "\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            # 填充\n",
    "            sequence = item[key]\n",
    "            padded = sequence + [pad_token_id] * (max_length_common - len(sequence))\n",
    "\n",
    "            # 除第一个填充token外，其余置为False\n",
    "            mask = torch.ones(len(padded)).bool()\n",
    "            mask[len(sequence):] = False\n",
    "\n",
    "            # mask prompt\n",
    "            if mask_prompt_tokens:\n",
    "                # response前包含有两个\\n\n",
    "                mask[:prompt.shape[0]+2] = False\n",
    "            \n",
    "            batch_data[key].append(torch.tensor(padded))\n",
    "            batch_data[f\"{key}_mask\"].append(mask)\n",
    "    \n",
    "    for key in [\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"]:\n",
    "        # stack to batch\n",
    "        tensor_stack = torch.stack(batch_data[key])\n",
    "\n",
    "        # 截断\n",
    "        if allowed_max_length is not None:\n",
    "            tensor_stack = tensor_stack[:, :allowed_max_length]\n",
    "        \n",
    "        batch_data[key] = tensor_stack.to(device)\n",
    "    \n",
    "    return batch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:58.876909Z",
     "start_time": "2025-04-29T14:02:58.873559Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预设部分参数\n",
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    mask_prompt_tokens=True,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.101229Z",
     "start_time": "2025-04-29T14:02:59.097187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
      "                'spelling given.',\n",
      " 'input': 'freind --> friend',\n",
      " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".',\n",
      " 'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get '\n",
      "             'it together, the correct spelling is \"friend\".',\n",
      " 'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".'}\n",
      "\n",
      "{'instruction': 'Edit the following sentence for grammar.',\n",
      " 'input': 'He go to the park every day.',\n",
      " 'output': 'He goes to the park every day.',\n",
      " 'rejected': 'He goes to the stupid park every single day.',\n",
      " 'chosen': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "# 测试数据\n",
    "example_data = data[:2]\n",
    "\n",
    "for i in example_data:\n",
    "    print()\n",
    "    pprint.pp(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.324677Z",
     "start_time": "2025-04-29T14:02:59.195353Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "example_dataset = PreferenceDataset(example_data, tokenizer)\n",
    "\n",
    "example_dataloader = DataLoader(\n",
    "    example_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.340679Z",
     "start_time": "2025-04-29T14:02:59.336702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.keys: dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch in example_dataloader:\n",
    "    break\n",
    "\n",
    "print(\"batch.keys:\", batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.404636Z",
     "start_time": "2025-04-29T14:02:59.398397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545]),\n",
       " tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.428283Z",
     "start_time": "2025-04-29T14:02:59.423644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='mps:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.494Z",
     "start_time": "2025-04-29T14:02:59.490717Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据查看函数\n",
    "def decode_tokens_from_batch(token_ids, tokenizer):\n",
    "    ids_in_python_list = token_ids.flatten().tolist()\n",
    "    return tokenizer.decode(ids_in_python_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.541266Z",
     "start_time": "2025-04-29T14:02:59.501008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"prompt\"][0],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.638541Z",
     "start_time": "2025-04-29T14:02:59.631541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:02:59.895287Z",
     "start_time": "2025-04-29T14:02:59.890714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.107226Z",
     "start_time": "2025-04-29T14:03:00.100778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen inputs: torch.Size([81])\n",
      "chosen mask:   torch.Size([81])\n"
     ]
    }
   ],
   "source": [
    "print(\"chosen inputs:\", batch[\"chosen\"][0].shape)\n",
    "print(\"chosen mask:  \", batch[\"chosen_mask\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.165483Z",
     "start_time": "2025-04-29T14:03:00.158604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False], device='mps:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen_mask\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.320690Z",
     "start_time": "2025-04-29T14:03:00.194491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "# 仅显示有效token\n",
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0][batch[\"chosen_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.355122Z",
     "start_time": "2025-04-29T14:03:00.347519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0][batch[\"rejected_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 创建训练集、验证集、测试集数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.524614Z",
     "start_time": "2025-04-29T14:03:00.385045Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 2  # 减少批次大小，以减少内存占用\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:00.757334Z",
     "start_time": "2025-04-29T14:03:00.551509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 94]) torch.Size([2, 94])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 99]) torch.Size([2, 99])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 88]) torch.Size([2, 88])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 97]) torch.Size([2, 97])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 89]) torch.Size([2, 89])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 101]) torch.Size([2, 101])\n",
      "torch.Size([2, 82]) torch.Size([2, 82])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 91]) torch.Size([2, 91])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 92]) torch.Size([2, 92])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 100]) torch.Size([2, 100])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 92]) torch.Size([2, 92])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 93]) torch.Size([2, 93])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 115]) torch.Size([2, 115])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 95]) torch.Size([2, 95])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 94]) torch.Size([2, 94])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 89]) torch.Size([2, 89])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 90]) torch.Size([2, 90])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 86]) torch.Size([2, 86])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 82]) torch.Size([2, 82])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 93]) torch.Size([2, 93])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 89]) torch.Size([2, 89])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 99]) torch.Size([2, 99])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 81]) torch.Size([2, 81])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 86]) torch.Size([2, 86])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 82]) torch.Size([2, 82])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 97]) torch.Size([2, 97])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 75]) torch.Size([2, 75])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 74]) torch.Size([2, 74])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 92]) torch.Size([2, 92])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 93]) torch.Size([2, 93])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 82]) torch.Size([2, 82])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 55]) torch.Size([2, 55])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 93]) torch.Size([2, 93])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 80]) torch.Size([2, 80])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 87]) torch.Size([2, 87])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 58]) torch.Size([2, 58])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 90]) torch.Size([2, 90])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 52]) torch.Size([2, 52])\n",
      "torch.Size([2, 72]) torch.Size([2, 72])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 99]) torch.Size([2, 99])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 104]) torch.Size([2, 104])\n",
      "torch.Size([2, 83]) torch.Size([2, 83])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 101]) torch.Size([2, 101])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 98]) torch.Size([2, 98])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 65]) torch.Size([2, 65])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 62]) torch.Size([2, 62])\n",
      "torch.Size([2, 54]) torch.Size([2, 54])\n",
      "torch.Size([2, 71]) torch.Size([2, 71])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 53]) torch.Size([2, 53])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 60]) torch.Size([2, 60])\n",
      "torch.Size([2, 76]) torch.Size([2, 76])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 73]) torch.Size([2, 73])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 79]) torch.Size([2, 79])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 68]) torch.Size([2, 68])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 56]) torch.Size([2, 56])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n",
      "torch.Size([2, 57]) torch.Size([2, 57])\n",
      "torch.Size([2, 61]) torch.Size([2, 61])\n",
      "torch.Size([2, 77]) torch.Size([2, 77])\n",
      "torch.Size([2, 67]) torch.Size([2, 67])\n",
      "torch.Size([2, 84]) torch.Size([2, 84])\n",
      "torch.Size([2, 85]) torch.Size([2, 85])\n",
      "torch.Size([2, 59]) torch.Size([2, 59])\n",
      "torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 70]) torch.Size([2, 70])\n",
      "torch.Size([2, 63]) torch.Size([2, 63])\n",
      "torch.Size([2, 69]) torch.Size([2, 69])\n",
      "torch.Size([2, 66]) torch.Size([2, 66])\n",
      "torch.Size([2, 78]) torch.Size([2, 78])\n"
     ]
    }
   ],
   "source": [
    "# 查看各个批次的context length\n",
    "print(\"Train loader:\")\n",
    "for batch in train_loader:\n",
    "    print(\n",
    "        batch[\"chosen\"].shape,\n",
    "        batch[\"rejected\"].shape,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 加载微调后的LLM进行DPO对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:03.451914Z",
     "start_time": "2025-04-29T14:03:00.780833Z"
    }
   },
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小\n",
    "    \"context_length\": 1024,  # 上下文长度\n",
    "    \"drop_rate\": 0.0,        # Dropout率\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:39.781721Z",
     "start_time": "2025-04-29T14:03:03.481334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载指令微调的模型，后续用于DPO对齐\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"gpt2-medium355M-sft.pth\",\n",
    "        map_location=device,\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:41.232537Z",
     "start_time": "2025-04-29T14:03:41.223369Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试输出\n",
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response\n",
    "that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:47.959919Z",
     "start_time": "2025-04-29T14:03:41.263837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response\n",
      "that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(prompt, tokenizer).to(device),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "\n",
    "response = token_ids_to_text(token_ids, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:03:48.016609Z",
     "start_time": "2025-04-29T14:03:48.010410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "# 仅提取有效回复\n",
    "def extract_response(response_text, input_text):\n",
    "    return response_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "response = extract_response(response, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:19.404184Z",
     "start_time": "2025-04-29T14:03:48.056812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model = model\n",
    "# 加载微调模型，作为参考模型，不进行参数更新\n",
    "reference_model = GPTModel(BASE_CONFIG)\n",
    "reference_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"gpt2-medium355M-sft.pth\",\n",
    "        map_location=device,\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "reference_model.to(device)\n",
    "reference_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 编写DPO损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:19.526617Z",
     "start_time": "2025-04-29T14:04:19.478203Z"
    }
   },
   "outputs": [],
   "source": [
    "# dpo loss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_dpo_loss(\n",
    "        model_chosen_logprobs,\n",
    "        model_rejected_logprobs,\n",
    "        reference_chosen_logprobs,\n",
    "        reference_rejected_logprobs,\n",
    "        beta=0.1,\n",
    "    ):\n",
    "    \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
    "\n",
    "    Args:\n",
    "        policy_chosen_logprobs: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
    "        policy_rejected_logprobs: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
    "        reference_chosen_logprobs: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
    "        reference_rejected_logprobs: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
    "        beta: Temperature parameter for the DPO loss; typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
    "        label_smoothing: conservativeness for DPO loss.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of three tensors: (loss, chosen_rewards, rejected_rewards).\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算模型和参考模型的logit差值 (log 除法 -> 减法)\n",
    "    model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
    "    reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs\n",
    "    logits = model_logratios - reference_logratios\n",
    "\n",
    "    # dps loss\n",
    "    losses = -F.logsigmoid(beta * logits)\n",
    "\n",
    "    # 跟踪训练效果\n",
    "    chosen_rewards = (model_chosen_logprobs - reference_chosen_logprobs).detach()\n",
    "    rejected_rewards = (model_rejected_logprobs - reference_rejected_logprobs).detach()\n",
    "\n",
    "    # 返回平均损失、平均奖励\n",
    "    return losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:20.818631Z",
     "start_time": "2025-04-29T14:04:20.805450Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "def compute_logprobs(logits, labels, selection_mask=None):\n",
    "    \"\"\"\n",
    "    Compute log probabilities.\n",
    "\n",
    "    Args:\n",
    "      logits: Tensor of shape (batch_size, num_tokens, vocab_size)\n",
    "      labels: Tensor of shape (batch_size, num_tokens)\n",
    "      selection_mask: Tensor for shape (batch_size, num_tokens)\n",
    "\n",
    "    Returns:\n",
    "      mean_log_prob: Mean log probability excluding padding tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    # 将输入右移一位作为标签\n",
    "    labels = labels[:, 1:].clone()\n",
    "\n",
    "    # 截断最后一个token，因为没有真实标签\n",
    "    logits = logits[:, :-1, :]\n",
    "\n",
    "    # 计算log概率\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # 获取对真实标签labels的预测概率log_probs\n",
    "    selected_log_probs = torch.gather(\n",
    "        input=log_probs,\n",
    "        dim=-1,\n",
    "        index=labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    # mask无效信息不计算Loss\n",
    "    if selection_mask is not None:\n",
    "        # 同labels，取右移一位后的mask\n",
    "        mask = selection_mask[:, 1:].clone()\n",
    "\n",
    "        # mask\n",
    "        selected_log_probs = selected_log_probs * mask\n",
    "\n",
    "        # 重新归一化\n",
    "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)\n",
    "\n",
    "        return avg_log_prob\n",
    "    else:\n",
    "        # 概率相乘 -> 对数概率相加 + 归一化\n",
    "        return selected_log_probs.mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:21.250220Z",
     "start_time": "2025-04-29T14:04:20.847208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4185) tensor(1.4185)\n"
     ]
    }
   ],
   "source": [
    "# 测试样例torch.gather\n",
    "# shape: (2, 3) \n",
    "logits = torch.tensor(\n",
    "    [[2.0, 1.0, 0.1],\n",
    "     [0.5, 2.5, 0.3]])\n",
    "targets = torch.tensor([0, 2])\n",
    "\n",
    "# 使用gather实现cross entropy，并对比\n",
    "# shape: (2, 3)\n",
    "log_softmax_logits = F.log_softmax(logits, dim=1)\n",
    "# shape: (2,)\n",
    "selected_log_probs = torch.gather(\n",
    "    input=log_softmax_logits,\n",
    "    dim=1,\n",
    "    index=targets.unsqueeze(1),\n",
    ").squeeze(1)\n",
    "manual_loss = -selected_log_probs.mean()\n",
    "\n",
    "# torch的cross entropy\n",
    "cross_entropy_loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "print(manual_loss, cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:21.280058Z",
     "start_time": "2025-04-29T14:04:21.275686Z"
    }
   },
   "outputs": [],
   "source": [
    "t = torch.tensor(\n",
    "  [[1., 2.,],\n",
    "   [3., 4.]]\n",
    ")\n",
    "\n",
    "m = torch.tensor(\n",
    "  [[1, 1],\n",
    "   [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:21.322699Z",
     "start_time": "2025-04-29T14:04:21.315147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input=t, dim=-1, index=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:21.780265Z",
     "start_time": "2025-04-29T14:04:21.772416Z"
    }
   },
   "outputs": [],
   "source": [
    "# 批训练中的dpo loss\n",
    "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
    "    \"\"\"Compute the DPO loss on an input batch\"\"\"\n",
    "\n",
    "    policy_chosen_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    policy_rejected_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "\n",
    "    # ref模型不更新梯度\n",
    "    with torch.no_grad():\n",
    "        ref_chosen_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"chosen\"]),\n",
    "            labels=batch[\"chosen\"],\n",
    "            selection_mask=batch[\"chosen_mask\"]\n",
    "        )\n",
    "        ref_rejected_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"rejected\"]),\n",
    "            labels=batch[\"rejected\"],\n",
    "            selection_mask=batch[\"rejected_mask\"]\n",
    "        )\n",
    "\n",
    "    # loss计算\n",
    "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
    "        model_chosen_logprobs=policy_chosen_log_probas,\n",
    "        model_rejected_logprobs=policy_rejected_log_probas,\n",
    "        reference_chosen_logprobs=ref_chosen_log_probas,\n",
    "        reference_rejected_logprobs=ref_rejected_log_probas,\n",
    "        beta=beta\n",
    "    )\n",
    "    return loss, chosen_rewards, rejected_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:42.496625Z",
     "start_time": "2025-04-29T14:04:21.923705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.6931, device='mps:0'), tensor(0., device='mps:0'), tensor(0., device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "# 查看测试loss\n",
    "with torch.no_grad():\n",
    "    loss = compute_dpo_loss_batch(batch, policy_model, reference_model, beta=0.1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:42.562057Z",
     "start_time": "2025-04-29T14:04:42.550360Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算整个data loader的loss\n",
    "def compute_dpo_loss_loader(data_loader, policy_model, reference_model, beta, num_batches=None):\n",
    "    \"\"\"Apply compute_dpo_loss_batch to a whole data loader\"\"\"\n",
    "\n",
    "    total_loss, total_chosen_rewards, total_rejected_rewards = 0., 0., 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            total_chosen_rewards += chosen_rewards.item()\n",
    "            total_rejected_rewards += rejected_rewards.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 返回平均结果\n",
    "    total_loss /= num_batches\n",
    "    total_chosen_rewards /= num_batches\n",
    "    total_rejected_rewards /= num_batches\n",
    "    return total_loss, total_chosen_rewards, total_rejected_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:42.594080Z",
     "start_time": "2025-04-29T14:04:42.583063Z"
    }
   },
   "outputs": [],
   "source": [
    "# 评估在train和val数据集上的效果\n",
    "def evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):\n",
    "    \"\"\"Compute the DPO loss for the training and validation dataset\"\"\"\n",
    "\n",
    "    policy_model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss, train_chosen_rewards, train_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=train_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=val_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "    res = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_chosen_reward\": train_chosen_rewards,\n",
    "        \"train_rejected_reward\": train_rejected_rewards,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_chosen_reward\": val_chosen_rewards,\n",
    "        \"val_rejected_reward\": val_rejected_rewards\n",
    "    }\n",
    "\n",
    "    policy_model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:04:42.640342Z",
     "start_time": "2025-04-29T14:04:42.622641Z"
    }
   },
   "outputs": [],
   "source": [
    "from previous_chapters import generate_and_print_sample\n",
    "\n",
    "\n",
    "# 偏好微调\n",
    "def train_model_dpo_simple(\n",
    "        policy_model, reference_model, train_loader, val_loader,\n",
    "        optimizer, num_epochs, beta,\n",
    "        eval_freq, eval_iter, start_context, tokenizer\n",
    "):\n",
    "    # 初始化\n",
    "    tracking = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_chosen_rewards\": [],\n",
    "        \"train_rejected_rewards\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_chosen_rewards\": [],\n",
    "        \"val_rejected_rewards\": [],\n",
    "        \"tokens_seen\": []\n",
    "    }\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # 经典训练流程\n",
    "            optimizer.zero_grad()\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 训练追踪\n",
    "            tokens_seen += batch[\"chosen\"].numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                res = evaluate_dpo_loss_loader(\n",
    "                    policy_model=policy_model,\n",
    "                    reference_model=reference_model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    beta=beta,\n",
    "                    eval_iter=eval_iter\n",
    "                )\n",
    "                tracking[\"train_losses\"].append(res[\"train_loss\"])\n",
    "                tracking[\"train_chosen_rewards\"].append(res[\"train_chosen_reward\"])\n",
    "                tracking[\"train_rejected_rewards\"].append(res[\"train_rejected_reward\"])\n",
    "                tracking[\"val_losses\"].append(res[\"val_loss\"])\n",
    "                tracking[\"val_chosen_rewards\"].append(res[\"val_chosen_reward\"])\n",
    "                tracking[\"val_rejected_rewards\"].append(res[\"val_rejected_reward\"])\n",
    "                tracking[\"tokens_seen\"].append(tokens_seen)\n",
    "                train_reward_margin = res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"]\n",
    "                val_reward_margin = res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"]\n",
    "\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {res['train_loss']:.3f}, Val loss {res['val_loss']:.3f}, \"\n",
    "                    f\"Train reward margins {train_reward_margin:.3f}, \"\n",
    "                    f\"Val reward margin {val_reward_margin:.3f}\"\n",
    "                )\n",
    "\n",
    "        # 每个epoch后，测试模型的生成效果\n",
    "        generate_and_print_sample(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=loss.device,\n",
    "            start_context=start_context\n",
    "        )\n",
    "\n",
    "    return tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T13:38:06.311316Z",
     "start_time": "2025-04-29T13:35:55.150047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6931471824645996\n",
      "Validation loss: 0.6931471824645996\n",
      "Train reward margin: 0.0\n",
      "Val reward margin: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 打印训练前的模型表现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "res = evaluate_dpo_loss_loader(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    beta=0.1,\n",
    "    eval_iter=5\n",
    ")\n",
    "\n",
    "print(\"Training loss:\", res[\"train_loss\"])\n",
    "print(\"Validation loss:\", res[\"val_loss\"])\n",
    "\n",
    "print(\"Train reward margin:\", res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"])\n",
    "print(\"Val reward margin:\", res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T13:42:00.721710Z",
     "start_time": "2025-04-29T13:41:57.773213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "Correct response:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "Model response:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "Correct response:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "Model response:\n",
      ">> Dance is a verb.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "Correct response:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "Model response:\n",
      ">> The book is a book.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看val数据集上的具体case\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-29T14:04:42.670106Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.693, Val loss 0.693, Train reward margins 0.001, Val reward margin 0.000\n",
      "Ep 1 (Step 000005): Train loss 0.693, Val loss 0.693, Train reward margins -0.001, Val reward margin 0.003\n",
      "Ep 1 (Step 000010): Train loss 0.692, Val loss 0.693, Train reward margins 0.021, Val reward margin 0.008\n",
      "Ep 1 (Step 000015): Train loss 0.692, Val loss 0.692, Train reward margins 0.032, Val reward margin 0.017\n",
      "Ep 1 (Step 000020): Train loss 0.691, Val loss 0.692, Train reward margins 0.033, Val reward margin 0.026\n",
      "Ep 1 (Step 000025): Train loss 0.690, Val loss 0.692, Train reward margins 0.056, Val reward margin 0.032\n",
      "Ep 1 (Step 000030): Train loss 0.691, Val loss 0.691, Train reward margins 0.049, Val reward margin 0.037\n",
      "Ep 1 (Step 000035): Train loss 0.693, Val loss 0.691, Train reward margins -0.002, Val reward margin 0.041\n",
      "Ep 1 (Step 000040): Train loss 0.693, Val loss 0.691, Train reward margins 0.010, Val reward margin 0.044\n",
      "Ep 1 (Step 000045): Train loss 0.689, Val loss 0.691, Train reward margins 0.084, Val reward margin 0.050\n",
      "Ep 1 (Step 000050): Train loss 0.691, Val loss 0.690, Train reward margins 0.039, Val reward margin 0.056\n",
      "Ep 1 (Step 000055): Train loss 0.683, Val loss 0.690, Train reward margins 0.198, Val reward margin 0.061\n",
      "Ep 1 (Step 000060): Train loss 0.690, Val loss 0.690, Train reward margins 0.059, Val reward margin 0.065\n",
      "Ep 1 (Step 000065): Train loss 0.688, Val loss 0.690, Train reward margins 0.113, Val reward margin 0.070\n",
      "Ep 1 (Step 000070): Train loss 0.684, Val loss 0.689, Train reward margins 0.190, Val reward margin 0.080\n",
      "Ep 1 (Step 000075): Train loss 0.684, Val loss 0.688, Train reward margins 0.182, Val reward margin 0.099\n",
      "Ep 1 (Step 000080): Train loss 0.684, Val loss 0.688, Train reward margins 0.195, Val reward margin 0.107\n",
      "Ep 1 (Step 000085): Train loss 0.689, Val loss 0.688, Train reward margins 0.077, Val reward margin 0.112\n",
      "Ep 1 (Step 000090): Train loss 0.685, Val loss 0.687, Train reward margins 0.162, Val reward margin 0.116\n",
      "Ep 1 (Step 000095): Train loss 0.688, Val loss 0.687, Train reward margins 0.114, Val reward margin 0.120\n",
      "Ep 1 (Step 000100): Train loss 0.669, Val loss 0.687, Train reward margins 0.497, Val reward margin 0.125\n",
      "Ep 1 (Step 000105): Train loss 0.684, Val loss 0.687, Train reward margins 0.187, Val reward margin 0.128\n",
      "Ep 1 (Step 000110): Train loss 0.671, Val loss 0.687, Train reward margins 0.457, Val reward margin 0.127\n",
      "Ep 1 (Step 000115): Train loss 0.678, Val loss 0.687, Train reward margins 0.311, Val reward margin 0.127\n",
      "Ep 1 (Step 000120): Train loss 0.690, Val loss 0.687, Train reward margins 0.056, Val reward margin 0.129\n",
      "Ep 1 (Step 000125): Train loss 0.665, Val loss 0.687, Train reward margins 0.584, Val reward margin 0.131\n",
      "Ep 1 (Step 000130): Train loss 0.687, Val loss 0.686, Train reward margins 0.119, Val reward margin 0.136\n",
      "Ep 1 (Step 000135): Train loss 0.669, Val loss 0.686, Train reward margins 0.495, Val reward margin 0.143\n",
      "Ep 1 (Step 000140): Train loss 0.676, Val loss 0.686, Train reward margins 0.344, Val reward margin 0.148\n",
      "Ep 1 (Step 000145): Train loss 0.686, Val loss 0.686, Train reward margins 0.141, Val reward margin 0.152\n",
      "Ep 1 (Step 000150): Train loss 0.653, Val loss 0.685, Train reward margins 0.838, Val reward margin 0.155\n",
      "Ep 1 (Step 000155): Train loss 0.662, Val loss 0.685, Train reward margins 0.637, Val reward margin 0.161\n",
      "Ep 1 (Step 000160): Train loss 0.683, Val loss 0.685, Train reward margins 0.214, Val reward margin 0.163\n",
      "Ep 1 (Step 000165): Train loss 0.680, Val loss 0.685, Train reward margins 0.265, Val reward margin 0.166\n",
      "Ep 1 (Step 000170): Train loss 0.645, Val loss 0.685, Train reward margins 1.030, Val reward margin 0.169\n",
      "Ep 1 (Step 000175): Train loss 0.675, Val loss 0.685, Train reward margins 0.376, Val reward margin 0.173\n",
      "Ep 1 (Step 000180): Train loss 0.668, Val loss 0.684, Train reward margins 0.532, Val reward margin 0.177\n",
      "Ep 1 (Step 000185): Train loss 0.680, Val loss 0.684, Train reward margins 0.264, Val reward margin 0.178\n",
      "Ep 1 (Step 000190): Train loss 0.685, Val loss 0.684, Train reward margins 0.166, Val reward margin 0.182\n",
      "Ep 1 (Step 000195): Train loss 0.670, Val loss 0.684, Train reward margins 0.491, Val reward margin 0.187\n",
      "Ep 1 (Step 000200): Train loss 0.674, Val loss 0.684, Train reward margins 0.402, Val reward margin 0.193\n",
      "Ep 1 (Step 000205): Train loss 0.651, Val loss 0.683, Train reward margins 0.887, Val reward margin 0.196\n",
      "Ep 1 (Step 000210): Train loss 0.687, Val loss 0.683, Train reward margins 0.140, Val reward margin 0.197\n",
      "Ep 1 (Step 000215): Train loss 0.664, Val loss 0.683, Train reward margins 0.642, Val reward margin 0.199\n",
      "Ep 1 (Step 000220): Train loss 0.646, Val loss 0.683, Train reward margins 1.011, Val reward margin 0.202\n",
      "Ep 1 (Step 000225): Train loss 0.680, Val loss 0.683, Train reward margins 0.263, Val reward margin 0.207\n",
      "Ep 1 (Step 000230): Train loss 0.645, Val loss 0.683, Train reward margins 1.023, Val reward margin 0.211\n",
      "Ep 1 (Step 000235): Train loss 0.662, Val loss 0.683, Train reward margins 0.658, Val reward margin 0.215\n",
      "Ep 1 (Step 000240): Train loss 0.655, Val loss 0.682, Train reward margins 0.801, Val reward margin 0.222\n",
      "Ep 1 (Step 000245): Train loss 0.666, Val loss 0.682, Train reward margins 0.562, Val reward margin 0.227\n",
      "Ep 1 (Step 000250): Train loss 0.678, Val loss 0.682, Train reward margins 0.319, Val reward margin 0.230\n",
      "Ep 1 (Step 000255): Train loss 0.689, Val loss 0.682, Train reward margins 0.095, Val reward margin 0.233\n",
      "Ep 1 (Step 000260): Train loss 0.682, Val loss 0.682, Train reward margins 0.253, Val reward margin 0.236\n",
      "Ep 1 (Step 000265): Train loss 0.678, Val loss 0.681, Train reward margins 0.310, Val reward margin 0.247\n",
      "Ep 1 (Step 000270): Train loss 0.687, Val loss 0.681, Train reward margins 0.127, Val reward margin 0.257\n",
      "Ep 1 (Step 000275): Train loss 0.653, Val loss 0.680, Train reward margins 0.832, Val reward margin 0.276\n",
      "Ep 1 (Step 000280): Train loss 0.681, Val loss 0.679, Train reward margins 0.255, Val reward margin 0.291\n",
      "Ep 1 (Step 000285): Train loss 0.688, Val loss 0.678, Train reward margins 0.098, Val reward margin 0.306\n",
      "Ep 1 (Step 000290): Train loss 0.646, Val loss 0.678, Train reward margins 1.016, Val reward margin 0.312\n",
      "Ep 1 (Step 000295): Train loss 0.650, Val loss 0.678, Train reward margins 0.994, Val reward margin 0.320\n",
      "Ep 1 (Step 000300): Train loss 0.648, Val loss 0.677, Train reward margins 0.974, Val reward margin 0.327\n",
      "Ep 1 (Step 000305): Train loss 0.658, Val loss 0.677, Train reward margins 0.783, Val reward margin 0.332\n",
      "Ep 1 (Step 000310): Train loss 0.620, Val loss 0.677, Train reward margins 1.699, Val reward margin 0.336\n",
      "Ep 1 (Step 000315): Train loss 0.635, Val loss 0.676, Train reward margins 1.300, Val reward margin 0.345\n",
      "Ep 1 (Step 000320): Train loss 0.630, Val loss 0.676, Train reward margins 1.365, Val reward margin 0.358\n",
      "Ep 1 (Step 000325): Train loss 0.621, Val loss 0.675, Train reward margins 1.565, Val reward margin 0.368\n",
      "Ep 1 (Step 000330): Train loss 0.658, Val loss 0.675, Train reward margins 0.747, Val reward margin 0.376\n",
      "Ep 1 (Step 000335): Train loss 0.608, Val loss 0.675, Train reward margins 1.902, Val reward margin 0.382\n",
      "Ep 1 (Step 000340): Train loss 0.679, Val loss 0.674, Train reward margins 0.292, Val reward margin 0.386\n",
      "Ep 1 (Step 000345): Train loss 0.660, Val loss 0.674, Train reward margins 0.707, Val reward margin 0.389\n",
      "Ep 1 (Step 000350): Train loss 0.660, Val loss 0.674, Train reward margins 0.697, Val reward margin 0.391\n",
      "Ep 1 (Step 000355): Train loss 0.607, Val loss 0.674, Train reward margins 1.889, Val reward margin 0.395\n",
      "Ep 1 (Step 000360): Train loss 0.620, Val loss 0.674, Train reward margins 1.552, Val reward margin 0.398\n",
      "Ep 1 (Step 000365): Train loss 0.682, Val loss 0.674, Train reward margins 0.257, Val reward margin 0.400\n",
      "Ep 1 (Step 000370): Train loss 0.644, Val loss 0.674, Train reward margins 1.093, Val reward margin 0.403\n",
      "Ep 1 (Step 000375): Train loss 0.666, Val loss 0.673, Train reward margins 0.572, Val reward margin 0.412\n",
      "Ep 1 (Step 000380): Train loss 0.617, Val loss 0.673, Train reward margins 1.721, Val reward margin 0.422\n",
      "Ep 1 (Step 000385): Train loss 0.670, Val loss 0.672, Train reward margins 0.497, Val reward margin 0.428\n",
      "Ep 1 (Step 000390): Train loss 0.672, Val loss 0.672, Train reward margins 0.484, Val reward margin 0.432\n",
      "Ep 1 (Step 000395): Train loss 0.653, Val loss 0.672, Train reward margins 0.916, Val reward margin 0.433\n",
      "Ep 1 (Step 000400): Train loss 0.584, Val loss 0.672, Train reward margins 2.544, Val reward margin 0.433\n",
      "Ep 1 (Step 000405): Train loss 0.594, Val loss 0.672, Train reward margins 2.293, Val reward margin 0.434\n",
      "Ep 1 (Step 000410): Train loss 0.666, Val loss 0.672, Train reward margins 0.584, Val reward margin 0.438\n",
      "Ep 1 (Step 000415): Train loss 0.649, Val loss 0.672, Train reward margins 0.958, Val reward margin 0.447\n",
      "Ep 1 (Step 000420): Train loss 0.628, Val loss 0.671, Train reward margins 1.543, Val reward margin 0.459\n",
      "Ep 1 (Step 000425): Train loss 0.671, Val loss 0.670, Train reward margins 0.490, Val reward margin 0.471\n",
      "Ep 1 (Step 000430): Train loss 0.639, Val loss 0.670, Train reward margins 1.237, Val reward margin 0.478\n",
      "Ep 1 (Step 000435): Train loss 0.614, Val loss 0.670, Train reward margins 1.778, Val reward margin 0.485\n",
      "Ep 1 (Step 000440): Train loss 0.589, Val loss 0.669, Train reward margins 2.410, Val reward margin 0.494\n",
      "Ep 1 (Step 000445): Train loss 0.570, Val loss 0.669, Train reward margins 2.871, Val reward margin 0.502\n",
      "Ep 1 (Step 000450): Train loss 0.617, Val loss 0.669, Train reward margins 1.738, Val reward margin 0.511\n",
      "Ep 1 (Step 000455): Train loss 0.633, Val loss 0.668, Train reward margins 1.459, Val reward margin 0.521\n",
      "Ep 1 (Step 000460): Train loss 0.596, Val loss 0.668, Train reward margins 2.202, Val reward margin 0.527\n",
      "Ep 1 (Step 000465): Train loss 0.677, Val loss 0.668, Train reward margins 0.328, Val reward margin 0.531\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a metaphor.  ### Input: The book is very interesting.  ### Response: The book is a treat.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the Netherlands?  ### Response\n",
      "Training completed in 6.609 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# batch_size从 8 --> 2时，学习率调整为原本的0.25，同时增大beta=0.2\n",
    "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6 * 0.25, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "tracking = train_model_dpo_simple(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    beta=0.1,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[2]),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.3f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "# 绘制loss曲线\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(tracking[\"train_losses\"]))\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=tracking[\"train_losses\"],\n",
    "    val_losses=tracking[\"val_losses\"],\n",
    "    label=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制reward margin曲线\n",
    "train_reward_margins = [i-j for i, j in zip(tracking[\"train_chosen_rewards\"], tracking[\"train_rejected_rewards\"])]\n",
    "val_reward_margins = [i-j for i, j in zip(tracking[\"val_chosen_rewards\"], tracking[\"val_rejected_rewards\"])]\n",
    "\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=train_reward_margins,\n",
    "    val_losses=val_reward_margins,\n",
    "    label=\"reward margins\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "Correct response:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "Reference model response:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "Policy model response:\n",
      ">> The meal is prepared by the chef every day.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "Correct response:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "Reference model response:\n",
      ">> Dance is a verb.\n",
      "\n",
      "Policy model response:\n",
      ">> The input 'Dance' could be classified as a verb.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "Correct response:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "Reference model response:\n",
      ">> The book is a book.\n",
      "\n",
      "Policy model response:\n",
      ">> The book is a treat.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接查看微调后的模型输出结果\n",
    "# 验证集\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "    # 微调前的模型效果\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 微调后的模型效果\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比效果\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Reference model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Policy model response:\n",
      ">> The car is as fast as an elephant.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Reference model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Policy model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Reference model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Policy model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接查看微调后的模型输出结果\n",
    "# 测试集\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    # 微调前的模型效果\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 微调后的模型效果\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # 对比效果\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
