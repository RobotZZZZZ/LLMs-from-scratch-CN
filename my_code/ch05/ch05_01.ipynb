{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch05/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch05\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估文本生成大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 用GPT来生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "# 124M模型配置\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 预测模式，dropout层不起作用\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# text -> ids\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "# ids -> text\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# 生成文本测试\n",
    "start_context = \"Every effort moves you\"\n",
    "# 使用gpt2的tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# 将文本转换为token ids, 并输入模型\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    # 生成10个新token\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "# 将模型结果ids转换为文本\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成的损失：交叉熵(cross-entropy)和困惑度（perplexity）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一组测试输入和目标，以ids list的形式表式\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 计算当前inputs的预测的下一个token的概率\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "# 当输入的shape为[2, 3, 50257]时，对于每个输入的每个token，预测下一个token的概率\n",
    "# 由于使用了causal mask，每个token的预测只依赖于它前面的token\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# 取max，得到预测的下一个token\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# 将预测的ids转换为文本，与targets对比\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# 查看当前样本的targets的概率\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算对数概率\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 计算平均对数概率\n",
    "# 在对数概率下，越接近0，表示预测越准确\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 负平均对数概率, 即交叉熵损失\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 查看logits和targets的shape\n",
    "# (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "# (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 使用torch的cross_entropy计算交叉熵损失\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "# 与neg_avg_log_probas相同\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# 计算困惑度, 困惑度是交叉熵的指数\n",
    "perplexity = torch.exp(loss)\n",
    "# 困惑度越小，表示预测越准确\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练数据\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 查看文本数据\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# 统计文本长度及编码后的token个数\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建dataloader\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 训练集\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速检测(sanity check)\n",
    "# 检查训练集和验证集的token个数是否足够\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 确认数据导入成功\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# 另一个方式，确认数据导入成功\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算batch loss\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# 计算数据集的loss\n",
    "def calc_loss_loader(data_loader, model ,device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若有GPU，则使用GPU计算\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n",
      "Training loss: 10.987583054436577\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# 注意：\n",
    "# 如果取消注释以下代码块，代码可以在 Apple Silicon 芯片上运行（如果适用），\n",
    "# 在 M3 MacBook Air 上测量速度大约是 Apple CPU 的两倍。\n",
    "# 然而，计算得到的损失值可能会略有不同。\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "   train_loss = calc_loss_loader(train_loader, model, device)\n",
    "   val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算batch loss\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            # 更新token计数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            # 更新全局步数\n",
    "            global_step += 1\n",
    "            # 每eval_freq个batch，计算一次loss, 查看训练效果\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                # 记录loss\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                # 记录token计数\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每个epoch结束，生成和打印文本\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "# 模型评估\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# 生成和打印文本\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Total training time: 1.45 minutes\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "# 训练模型\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# 绘制Loss\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
