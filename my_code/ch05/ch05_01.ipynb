{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/ch05/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "# 使用sys.path添加上级目录\n",
    "import sys\n",
    "import os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(package_path, \"ch05\", \"01_main-chapter-code\")\n",
    "print(file_path)\n",
    "sys.path.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估文本生成大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 用GPT来生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "# 124M模型配置\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 预测模式，dropout层不起作用\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# text -> ids\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "# ids -> text\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# 生成文本测试\n",
    "start_context = \"Every effort moves you\"\n",
    "# 使用gpt2的tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# 将文本转换为token ids, 并输入模型\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    # 生成10个新token\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "# 将模型结果ids转换为文本\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成的损失：交叉熵(cross-entropy)和困惑度（perplexity）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一组测试输入和目标，以ids list的形式表式\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 计算当前inputs的预测的下一个token的概率\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "# 当输入的shape为[2, 3, 50257]时，对于每个输入的每个token，预测下一个token的概率\n",
    "# 由于使用了causal mask，每个token的预测只依赖于它前面的token\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# 取max，得到预测的下一个token\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# 将预测的ids转换为文本，与targets对比\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# 查看当前样本的targets的概率\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算对数概率\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 计算平均对数概率\n",
    "# 在对数概率下，越接近0，表示预测越准确\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 负平均对数概率, 即交叉熵损失\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 查看logits和targets的shape\n",
    "# (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "# (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 使用torch的cross_entropy计算交叉熵损失\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "# 与neg_avg_log_probas相同\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# 计算困惑度, 困惑度是交叉熵的指数\n",
    "perplexity = torch.exp(loss)\n",
    "# 困惑度越小，表示预测越准确\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练数据\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 查看文本数据\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# 统计文本长度及编码后的token个数\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建dataloader\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 训练集\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速检测(sanity check)\n",
    "# 检查训练集和验证集的token个数是否足够\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 确认数据导入成功\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# 另一个方式，确认数据导入成功\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算batch loss\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# 计算数据集的loss\n",
    "def calc_loss_loader(data_loader, model ,device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若有GPU，则使用GPU计算\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n",
      "Training loss: 10.987583054436577\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# 注意：\n",
    "# 如果取消注释以下代码块，代码可以在 Apple Silicon 芯片上运行（如果适用），\n",
    "# 在 M3 MacBook Air 上测量速度大约是 Apple CPU 的两倍。\n",
    "# 然而，计算得到的损失值可能会略有不同。\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "   train_loss = calc_loss_loader(train_loader, model, device)\n",
    "   val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算batch loss\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            # 更新token计数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            # 更新全局步数\n",
    "            global_step += 1\n",
    "            # 每eval_freq个batch，计算一次loss, 查看训练效果\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                # 记录loss\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                # 记录token计数\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每个epoch结束，生成和打印文本\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "# 模型评估\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# 生成和打印文本\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Total training time: 0.67 minutes\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "# 训练模型\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# 绘制Loss\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 假设输入文本为 \"every effort moves you\",\n",
    "# 同时假设模型的输出概率如下:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "# softmax归一化\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 生成的下一个token\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    # 从概率分布中采样\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    # 统计单词文本的频率\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "# 统计采样1000次时的单词频率\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入温度系数的softmax\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 不同的温度系数\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+sElEQVR4nO3dB5RT1fY/8E0TpEnvIE1BpEkHKSodFEFRmoC0JwKCIiggVao0gcdQpAnS5QkqShGedJBepCpFePSOAgLC/a/v/q2bfxIyw8wkmZyb+X7WymLmzkxyJ2Sy7zlnn70TWJZlCRERERkpYahPgIiIiCLHQE1ERGQwBmoiIiKDMVATEREZjIGaiIjIYAzUREREBmOgJiIiMhgDNRERkcESSzzz4MEDOXPmjKRKlUoSJEgQ6tMhIqJ4yLIs+fPPPyVbtmySMGHUY+Z4F6gRpHPmzBnq0yAiIpJTp05Jjhw5ovyeeBeoMZK2n5zUqVOH+nSIiCgeunHjhg4a7ZgUlXgXqO3pbgRpBmoiIgql6CzBMpmMiIjIYCEN1OvWrZNXXnlFF9NxVbFkyZJH/syaNWukRIkSkjRpUsmfP798+eWXcXKuRERE8S5Q37x5U4oVKyYRERHR+v7jx49L3bp15cUXX5Tdu3fL+++/L23btpUVK1YE/VyJiIhCIaRr1LVr19ZbdE2aNEny5Mkjo0aN0s+feeYZ2bBhg3z++edSs2bNIJ4pEcX1Nsq7d++G+jSIYi1JkiSSKFEiCQRHJZNt3rxZqlWr5nEMARoj68jcuXNHb+6ZdkRkLgRozJ4hWBM5WZo0aSRLlix+1+xwVKA+d+6cZM6c2eMYPkfwvX37tjz++OMP/czQoUNlwIABcXiWRORPEYizZ8/qSARbVx5VCILI1NfxrVu35MKFC/p51qxZ40+gjo2ePXtK165dH9q7RkTm+eeff/QNDgmmyZMnD/XpEMWaPXBEsM6UKZNf0+COCtSYQjh//rzHMXyO/dC+RtOA7HDciIzS/4kovnZd4qv79+/rv4899lioT4XIb/bF5r179/wK1I6aVypfvrysXr3a49hPP/2kx4kofLAOP4WDBAF6HYc0UP/111+6zQo3QAIJPj558qRr2rpFixau72/fvr0cO3ZMPvroIzl06JBMmDBBFi5cKB988EHIfgciIqJgCmmg3r59uzz33HN6A6wl4+O+ffvq50gqsYM2YGvWDz/8oKNo7L/GNq2pU6dyaxYREYWtkK5Rv/DCC5odFxlfVcfwM7t27QrymRGRSXL3+CFOH+/EsLoBm97s16+f9O/fX8JJ7ty5dVtsVFtjTde5c2fZuHGj/Prrr1qTw57ZNZGjksmIiEyDmT/bggULdEbw8OHDrmMpU6YUJ8CgCcl8iRMnjtM986FMHGzdurX88ssvsnfvXjGZo5LJiIhM3I1i35544gkdYbsfmz9/vo7YkiVLJgULFtTcGtuJEyf0+5FrU6lSJd29Urp0aTly5Ihs27ZNSpUqpYEeFRwvXrzo+rm3335b6tevrzUiMmbMqDtfkMPjXs0NBWNQRwJLhrhfLBcuWrTIo28CHnvZsmVSsmRJ3R2DSo9Hjx6VV199VWtU4LFxPqtWrfKY1fzjjz80Nwg/b88oYNagePHiHs/NmDFjdPTtfd6DBw/WLXgFChRwtR1+8803tUBIunTp9PHx3ATTuHHjpGPHjpI3b14xHQM1EVGQzJkzR0fYCEwHDx6UIUOGSJ8+fWTmzJkPTY/37t1bdu7cqSPapk2batLs2LFjZf369fL777+7cnds2AGD+0TAnTdvnnzzzTcexZ0QpGfNmqWll/fv36+B9a233pK1a9d63E+PHj1k2LBhel9FixbVJN86dero/WOZsVatWto8yc4XwuPkyJFDPv30U51NcJ9RiA7cL2YckGu0dOlS3bqEPCP0ZcbviuloXCDgcaMqI5syZcoob7hwCRec+iYiChIEYCS9vvbaa/o5RrcHDhyQyZMnS8uWLV3f161bN1dSbJcuXaRJkyYa0J5//nk91qZNm4dydjBlPH36dN2r++yzz2rg7N69uwwcOFCDHy4KMBK2t69i5IgRMx67SpUqrvvBz1WvXt31OUa0GH3bcH+LFy+W7777Tjp16qRfx55gBFbMGMRUihQpNAnYnvKePXu2jv5xzB6dz5gxQ0fXuAipUaOGz/t51JoyZhnCBQM1EVGQugNiGhlBtl27dh7V1zBF7g4jWZtdJrlIkSIex+xylDYEU/fqbQjIGA1jGhn/osKbewAGjFDtXTY2TK+7w89iGhs7bDBaxvmiRLP7Dhx/4PdyX5fes2ePzhgg8Lv7+++/9fmLDNocxxcM1EREQYCAB1OmTJGyZct6fM27ShU6LdnsUaX3sZg0KbEfG8E2e/bsHl/zrtSIEa47jO4xLT1y5EgNhljfbtiw4SO7maEuu/cuHozsvXk/Hs4Va+RYJvCG9ffIPCpJD9P8mPYPBwzURERBgFEwEqZQpKlZs2YBv3+MRN2bEW3ZskWDF3oZYHoaARmjYPdp7ujAGjGSvho0aOAKpN6JXRgR2+Ve3YMqGichWNsXG9HZ8lSiRAnNlkc97JhMV+/m1DcREfkLyV3Yr4upbiRHoeUuCj1dvXrVo1lQbGCEi2l1JKEhkGI9HGvIGNliGhkjYySQYSResWJFuX79ugZhBDD39XFvTz31lCaMIYEMARfJb96jeWRyr1u3Tho3bqwXBBkyZNBscGSmDx8+XEfgy5cv14zyRwVMXMSMGDFCM72xXo5ENWSV4xyQUJcjR46gTH1juh0XIbi4wAWPHfgLFSpkXK15Zn0TEQVJ27ZtNUkKyVFYm8XoFklhSCrzV9WqVTWoVq5cWRo1aiT16tXzKKyCJDAEWWR/Y3sYLhQwFf6oxx49erSkTZtWKlSooMEaSW4Y9bpDQMXFQb58+VzT03gMbD2LiIjQ9fOtW7fqxcKjYJ0dQT9XrlyadIf7wQUI1qiDOSpu27atrtcjuQ7b4ewqmWfOnBHTJLCiKg0WhtDmEle3uLoMp6kRchh2z/IJb86o+Y9ggn3H5Bumpq9duyZLliwJ9alQLF/PMYlFHFETEREZjIGaiIjIYEwmIyJyGF8Niyh8cURNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzURkR9QDzuqm3tZz3CBWt9jxowRJzt58qTUrVtXS5iiIQh6eaOlZ1QGDx6spVXxM+iXHVe4j5qInF1yNSiPF/0yrujZbEMXqL59+8rhw4ej3Y7RFKgmjY5YiRPHXVhAY5FQNMC4f/++BuksWbLIpk2b9P+wRYsW2lp0yJAhUZ7vG2+8ob2/p02bFmfnyxE1EZEf8GZv31C7GaNo92Pz58/XRhOo9VywYEFtXGFDYwt8/8KFC6VSpUrasrJ06dLaJGLbtm1SqlQpDfS1a9fWzlTutb7r16+v3bnQFAO1otu3b+/RMxodr9CQA3Wmcb9olLFo0SLX19esWaOPjQ5X6AeNLlgbNmyQo0ePaicrtOnEY+N8Vq1a5fo5dMlCdyt05rJnDQAzB8WLF/d4bjDqxujb+7wxMkUL0AIFCujxU6dOyZtvvqmjVLToxON7t9YMpJUrV8qBAwdk9uzZes54ftHEBA1Fouq7jecbvzcarMQlBmoioiCZM2eOjrARmA4ePKijNXS0mjlzpsf3oUUl2lXu3LlTR7RNmzbVFo9jx46V9evXa0tG3I+71atX630i4M6bN0/bQiKQ2BCkZ82aJZMmTZL9+/drgHnrrbdk7dq1HvfTo0cPGTZsmN5X0aJFtfVjnTp19P537dqlXbfQRQtTxYDHQetJdNDCSNR9RiE6cL+Ycfjpp59k6dKlcu/ePe3Qhdac+F3RihMXCHjcqIJmypQpo7zhwiUymzdv1mCLixEbzgGNMvBcmYZT30REQYIAPGrUKG3fCBjdYiSH1oruPaHRDhKBArp06SJNmjTRgPb888/rMbR99C4biinj6dOn63rps88+q4ET66wYGSL44aIAI2FM00LevHl1xIzHRrtNG36uevXqrs8xosXo24b7W7x4sXz33Xfa7xpfT5QokQZWzBjEVIoUKbT1pz3ljVEtRv84Zo/O0RYUo2tchNSoUcPn/dj9oyMTVUcq9KB2D9Jgf46vmYaBmogoCG7evKnTyAiy7dq1cx1HwhKmyN1hJOsdMNynV3HswoULHj+DYIogbUNAxmgY08j499atWx4BGDBCRc9ld5hed4efxTQ2eldjtIzzvX37tmtE7S/8Xu7r0nv27NEZAwR+7xaReP4ikz9/fokvGKiJiIIAAQ+mTJkiZcuW9fgaRqTukMRks0eV3scw6ozpYyPYZs+e3eNrWIv2HuG6w+ge09IjR47UYIj17YYNG0Y5DQ0JEybUhDR3GNl78348nCvWyLFM4A3r75F5VJIepvkx7e8LZgK2bt3qcez8+fOur5mGgZqIKAgwCkbC1LFjx6RZs2YBv3+MRDHSRSCFLVu2aPDKmTOnTk8jIGMU7D7NHR1YI0bSV4MGDVyB1DuxCyNiZE57B1VMGyNY2xcbj5qehhIlSmi2PLZIRTVdHcipb8w+IG8AsxR4XMDFCX6mUKFCYhoGaiKiIEFyV+fOnXWqG8lRd+7cke3bt8vVq1ela9euft03RriYVkcSGgIp1sOxhoyRLaaRMTJGAhlG4hUrVpTr169rEEYwcl8f9/bUU09pwhgSyBBwkfzmPZpHJve6deukcePGekGQIUMGzQZHZvrw4cN1BL58+XLNKH9U8MVFzIgRIzTTG+vlSFRDVjnOAQl1OXLkCPjUN9a9EZCbN2+u54sLDDyPHTt2dM04YMSNLVvIFbBnJXDhc+XKFf0XFyr2xQLOJZjb8EKe9Y10ePynY+sCpoe8pyO8Id0fKf24isSVI16IWMsgIjJN27ZtNUkKyVFYm8XoFklhSCrzV9WqVTWoVq5cWRo1aiT16tXzKK6CJDAEWWR/Y3sYLhQwFf6oxx49erSkTZtWC3sgWCPJDaNedwiouDjIly+fa3oaj4GtZ3hPx/o53stxsfAoWGdH0M+VK5cm3eF+cAGC9/WYjLBjAksPyDjHvxhdY5ocQRm/lw1r/MhOd5++R+Y91vhxUYSZBnyMGy6+gimB5b2oEIcw3YEnB+sICNIIwl9//bU+OfZ0hLu5c+dK69atNdMRLyLsNcQUDa7q8OKKDqTf4+oWV5fBehEQ+VXAIwbFNsIN3pyPHz+uwQQX7+Qb3veuXbsmS5YsCfWpUCxfzzGJRSEdUSO4IhuyVatWOg2BgI2rKwRiX1BBBtsVsMcQo3BMX2Abw6NG4URERE4VskCN9ZUdO3ZItWrV/v/JJEyon2Mzui8YReNn7MCMJI0ff/xRN+cTERGFo5Alk126dEkX431tOj906JDPn8FIGj+HxAjM2GN/H6rP9OrVK9LHQfIGbu7TDURETuZd/ITCW8iTyWICVWpQbQcJCyi1h6xAJEcgaSIySKTAOoB9QwIaERGRU4RsRI10fmTc2ZvMbfg8sg3nyGBEOj0yKQFZlKj+869//Us++eQTnTr31rNnT49tEBhRM1gTEZFThGxEjQ3zqEaDPWo27NXD53ZtWm9Il/cOxnaFn8iS17EnDhl17jciIiKnCGnBE4x0sfEetWbLlCmj27MwQkYWOGDrFjaaY/oasKcPmeLYt4btXKgPi1E2jnuX5CMiIgoHIQ3U2KSPSjbYRI7KMOgLimo2doIZqr+4j6BROQaVcvDv6dOndaM9gjRKwREREYWjkBY8CQUWPCEjsOCJTyx4QuHk73AoeEJERERRY6AmIvIDluOiurnX3w4XqAyJnCInS+Dj/2r+/PliInbPIiLjFZlZJE4fb1/LfdH+3rNnz3r0L0DODfoV2ILZVSmQsAqKIlSJEyeO0wqV2AEUKjNmzNBmJbY0adKIiTiiJiLyA+o+2DesOWJk5n4MozR0hMIaZcGCBbVgkw0dqPD9CxculEqVKmlXwNKlS2vDoW3btumOGAT62rVra+Kte1OO+vXraxtNJNVijRNVGhH43Le7YscM1kdxv+hotWjRIo8CUnhstKLEVllsZd2wYYMcPXpUW04iqRePjfNZtWqV6+fQzhJtKNG50B6JAmYOkBDsDqNujL69zxsJwOjVjU6IcOrUKXnzzTc1UKKXNh7fuwd2MODx3P+vTM2LYKAmIgqSOXPm6AgbgengwYNaWRFbSmfOnOnxfWibiN0sqLiIES3KJaMX89ixY2X9+vW6FRX34w41J3CfCLjz5s3TSo0I3DYE6VmzZmmzo/3792tgRTvHtWvXetxPjx49ZNiwYXpfRYsW1faN6J+A+9+1a5eOOLG7BrtwAI+DHtFoCYnZBPcZhejA/WLG4aefftJWk2gjiVaa6KGN3xU9s3GBgMd1v/Dwhu+J6oYLl0dB/2kU38L2YDSDMjW3mlPfRERBggA8atQo7bMMGN0eOHBAJk+erDUkbOjbjGAFXbp00a6ACGjoFgjoz+xd3xtTxggu6Dj47LPPauDs3r27llRG8MNFAUbCdgGpvHnz6ogZj42+2Db8XPXq1V2fY0SL0bcN97d48WL57rvvpFOnTvp11K1AYI2simRUUqRIoT267Snv2bNn6+gfx+zROaakMdrFRUiNGjV83s/u3bujfJxHZVLj937ppZf0+Vu5cqV06NBBL1I6d+4spmGgJiIKAhRvwjQygiza+drQTAhT5O4wkrXZdSRQItn92IULFzx+BsEUQcaGgIxAg2lk/ItKju4BGDBCRcEod5hed4efxTQ2+ihgtIzzvX37tmtE7S/8Xu7r0nv27NEZAwR+761NeP4ikz9/fvEHZjZseE7w/zVixAgGaiKi+AIBD6ZMmaKVFN15V1JMkiSJ62N7VOl9DKPOmD42gi2qO7rDWrT3CNcdRveYlh45cqQGQ6xvN2zYMMppaEBxKu+pY4zsvXk/Hs4Va+RYJvCG9ffIPCpJD9P8mPaPLvwfYfYA3Ra9n6NQY6AmIgoCjIKRMHXs2DFp1qxZwO8fI1GMdBFIYcuWLRq80HQI09MINhgFu09zRwfWiJH01aBBA1cg9U7swogYGeLeQRUVJhGs7YuNR01PQ4kSJTRbPlOmTDEqQrXbz6lvX/eXNm1a44I0MFATEQUJkrswlYqpbiRHYbS2fft2uXr1qkdXv9jACBfT6khCQyDFejjWkDGyxTQyRsZIIMNIvGLFiloBC0EYAcx9fdzbU089pQljSCBDwMUUsfdoHpnc69atk8aNG2tgQ0IWssGRmT58+HAdgaMcNDLKHxUwcRGDKWdkemPdGIlqyCrHOSChLkeOHAGf+v7++++1U2O5cuU00xszCFjTx3NmImZ9ExEFCVryIkkKyVFYm8XoFklhSCrzV9WqVTWoVq5cWfsm1KtXz6O4CqZxEWSR/Y3tYbhQwFT4ox4bjY8wsqxQoYIGayS5YdTrDgEVFwf58uVzTU/jMbD1LCIiQtfPt27dGq3Ah3V2BP1cuXJp0h3uBxcgWKMOVpnnJEmS6HliXR9bypBgh98bFzsmYq1volBgrW+fWOs7ejA1fe3aNVmyZEmoT4WiwFrfRERE8QADNRERkcGYTEZE5DDexU8ovMVqRP3zzz8H/kyIiIgoMIEa2YPI9hs0aJBWwSEiIiKDAvXp06d1vx46saB+LNL30f3lUZVriIiiI55tRqEwZQXodRyrQI3N7dhIj0ouv/zyizz99NNa0BxVeLC5HxVziIhiyi6tyYt+Cge3bt16qBxsSJLJsBEeHVTSp0+vrdLQzQWb3rGRHHVW0dWFiCg60OIRBTBQ4QpvbqiyReTEkTSCNBqpoAuYd233OAvUKLb+7bffamBG+TV0YBk/fry2Z8MfGcravfHGG9rSjYgoOlCyMmvWrFokAmUkiZwMQTo2rUADEqjfe+89bVSOq4bmzZtrbdfChQt7dEdB5xVMhRMRxQQaPqA0Jqe/ycmSJEni90jar0CNUfK///1vrcsaWacRrGNzGxcRxQamvFlClOj/xGoBCIXLMa3tHaTRYBzF1e21ppi2VyMiIqIABOoXX3xRrly58tBxFBfH14iIiCiEgdq9Mbi7y5cv6/o0ERERSdyvUWNNGhCk0WbNfer7/v37snfvXu1hSkRERCEI1OidaY+oU6VKJY8//rhHpma5cuWkXbt2ATo1IiIiilGgnjFjhv6bO3du6datG6e5iYiITM36DlSQjoiI0MCPrRhly5aVrVu3Rvn9165dk44dO2pRBEy9o3zpjz/+GJBzISIicuyIGqVCV69eLWnTppXnnnvOZzKZbefOndG6zwULFkjXrl211CiC9JgxY7TBx+HDhyVTpkwPfT8KIFSvXl2/hoYg2bNn1+pFqP5CREQUrwP1q6++6koeq1+/fkAefPTo0bqm3apVK/0cAfuHH37QsqQ9evR46PtxHNvCNm3a5CpyjtE4ERFRuEpghaifHEbHKL6PkbF74G/ZsqVOb6OOuLc6depIunTp9Ofw9YwZM0rTpk3l448/jrRU2507d/Rmu3HjhuTMmVP3fKdOnTpIvx3RI/R/IoqvXY/LMyGiEEAsQoJ2dGJRyFrTXLp0Sbd0Zc6c2eM4Pj937pzPnzl27JgGdvwc1qX79Okjo0aNkkGDBkX6OEOHDtUnw74hSBMREYXd1DfWpqNal3bnq2pZIDx48EDXp7/44gsdQZcsWVJOnz4tI0aM0AQ3X3r27Knr4N4jaiIiorAK1Ej0CiQ07UCwPX/+vMdxfB5ZWzBkent3JHnmmWd0BI6pdOzl9oZ19cgahxAREYVNoMbacSAhqGJEjExye40aI2Z83qlTJ58/8/zzz8vcuXP1++yG8keOHNEA7itIExEROV2016gxZez+cVS36MKU9JQpU2TmzJly8OBBeffdd+XmzZuuLPAWLVro1LUNX8e0epcuXTRAI0N8yJAhuq+aiIhI4vsa9dmzZ3WNGPuWfa1X2806kOwVHY0aNZKLFy9K3759dfq6ePHisnz5cleC2cmTJ10jZ8Da8ooVK+SDDz6QokWL6j5qBG1kfRMREcXr7Vlr167VqWf0mcbHUTG5D3VMUuKJ/JG7xw+Rfu1EsqaR/yC3ZxGFvRsxiEXRHlG7B1+TAzEREVG8bcrh7urVqzJt2jRdW4ZChQrp2jIKkhAREVFgxKrgybp167R057hx4zRg44aP8+TJo18jIiKiEI6okWWNRLCJEye69jQjgaxDhw76tX379gXo9IiIiOK3WI2of//9d/nwww89Co/gY2y3wteIiIgohIEaLS/ttWl3OFasWLFAnBcRERHFZOp77969ro87d+6s+5cxei5Xrpwe27Jli0RERMiwYcOCc6ZERETxULT3UaPwCIqZPOrbY1LwJBS4j5riCvdRE1Gc7qM+fvx4dL+ViIiIAiTagfrJJ58M1GMSERFRsAuewIEDB7QeN1pMuqtXr54/d0tERET+BOpjx45JgwYNdL+0+7q13ajD5DVqIiKisN+ehYxvVCG7cOGCJE+eXPbv368VyUqVKiVr1qwJ/FkSERHFU7EaUW/evFn++9//SoYMGTQbHLeKFSvK0KFDdevWrl27An+mRERE8VCsRtSY2k6VKpV+jGB95swZV8LZ4cOHA3uGRERE8VisRtSFCxeWPXv26PR32bJlZfjw4fLYY4/JF198IXnz5g38WRIREcVTsQrUvXv3lps3b+rHn376qbz88stSqVIlSZ8+vSxYsCDQ50hERBRvxSpQ16xZ0/Vx/vz55dChQ3LlyhVJmzatK/ObiIiIQryPGk6dOqX/5syZMwCnQ0RERH4nk/3zzz/Sp08frVOaO3duveFjTInfu3cvNndJREREgRpRv/fee/LNN99oEln58uVdW7b69+8vly9flokTJ8bmbomIiCgQgXru3Lkyf/58qV27tutY0aJFdfq7SZMmDNREREShnPpOmjSpTnd7w3YtbNMiIiKiEAbqTp06ycCBA+XOnTuuY/h48ODB+jUiIiKK46nv1157zePzVatWSY4cOaRYsWL6OQqgoItW1apVA3RqREREFO1Ajaxud6+//rrH59yeRUREFMJAPWPGjCA8PBEREQWt4MnFixddTTgKFCggGTNm9OfuiIiIKBDJZKjz3bp1a8maNatUrlxZb9myZZM2bdrIrVu3YnOXREREFKhA3bVrV1m7dq18//33cu3aNb19++23euzDDz+M8f1FRETodq9kyZJpN66tW7dG6+ewlxu1xevXrx+L34KIiChMA/V//vMfmTZtmhY8SZ06td7q1KkjU6ZMkUWLFsXovtBtC4G/X79+snPnTs0iR9OPCxcuRPlzJ06ckG7dumnXLiIionAVq0CN6e3MmTM/dDxTpkwxnvoePXq0tGvXTlq1aiWFChWSSZMmSfLkyWX69OmR/sz9+/elWbNmMmDAAPa/JiKisBarQI363hgB//33365jt2/f1sBp1/6ODuy73rFjh1SrVu3/n1DChPo5aodHBj2wcVGANfFHQSGWGzdueNyIiIjCOut7zJgxUqtWrYcKnmCNecWKFdG+n0uXLuno2Ht0js/R49qXDRs26LT77t27o/UYQ4cO1QsIIiKieBOoixQpIr/99pvMmTPHFVDRjAPT0Y8//rgEy59//inNmzfXtfAMGTJE62d69uypa+A2jKhZnIWIiMI2UKPfdMGCBWXp0qW6tuwPBNtEiRLJ+fPnPY7j8yxZsjz0/UePHtUksldeecV17MGDB/pv4sSJdU93vnz5HmogghsREVG8WKNOkiSJx9q0P9Bpq2TJkrJ69WqPwIvPfa114wJh3759Ou1t3+rVqycvvviifsyRMhERhZtYTX137NhRPvvsM5k6daqOZP2BaemWLVtKqVKlpEyZMrr+jYIqyAKHFi1aSPbs2XWtGWvghQsX9vj5NGnS6L/ex4mIiMJBrKLstm3bdNS7cuVKXa9OkSKFx9e/+eabaN9Xo0aNtBRp37595dy5c1K8eHFZvny5K8Hs5MmTmglOREQUH8UqUGMU6909yx/oYR1ZH+s1a9ZE+bNffvllwM6DiIjI0YEa68cjRoyQI0eO6B7ol156Sfr37x/UTG8iIqL4LEZzyoMHD5ZevXpJypQpdd143Lhxul5NREREBoyoZ82aJRMmTJB33nlHP1+1apXUrVtXk8q4jkxEFN5y9/jB5/ETw+rG+bnEJzGKrkjsQvMNG0p9onvVmTNngnFuRERE8V6MAvU///yjW6S891WjCAoRERGFeOrbsix5++23PSp9ofhJ+/btPbZoxWR7FhEREQUoUKMwibe33norJndBREREwQrUM2bMiMm3ExERkZ+Yqk1ERGQwBmoiIiKDMVATEREZjIGaiIjIYAzUREREBmOgJiIiMhgDNRERkcEYqImIiAzGQE1ERGQwBmoiIiKDMVATEREZjIGaiIjIYAzUREREBmOgJiIiMhgDNRERkcEYqImIiAzGQE1ERGSwxKE+ASLyVGRmkUi/tq/lvjg9FyIKPY6oiYiIDMZATUREZDAjAnVERITkzp1bkiVLJmXLlpWtW7dG+r1TpkyRSpUqSdq0afVWrVq1KL+fiIjIyUK+Rr1gwQLp2rWrTJo0SYP0mDFjpGbNmnL48GHJlCnTQ9+/Zs0aadKkiVSoUEED+2effSY1atSQ/fv3S/bs2UPyOxARkW/MuQiDEfXo0aOlXbt20qpVKylUqJAG7OTJk8v06dN9fv+cOXOkQ4cOUrx4cSlYsKBMnTpVHjx4IKtXr47zcyciIgrrQH337l3ZsWOHTl+7TihhQv188+bN0bqPW7duyb179yRdunRBPFMiIqJ4OPV96dIluX//vmTOnNnjOD4/dOhQtO7j448/lmzZsnkEe3d37tzRm+3GjRt+njUREVE8mvr2x7Bhw2T+/PmyePFiXa/2ZejQofLEE0+4bjlz5ozz8yQiInJkoM6QIYMkSpRIzp8/73Ecn2fJkiXKnx05cqQG6pUrV0rRokUj/b6ePXvK9evXXbdTp04F7PyJiIjCOlA/9thjUrJkSY9EMDsxrHz58pH+3PDhw2XgwIGyfPlyKVWqVJSPkTRpUkmdOrXHjYiIyClCvj0LW7NatmypAbdMmTK6PevmzZuaBQ4tWrTQbVeYwgZsx+rbt6/MnTtX916fO3dOj6dMmVJvRERE4STkgbpRo0Zy8eJFDb4Iuth2hZGynWB28uRJzQS3TZw4UbPFGzZs6HE//fr1k/79+8f5+RMREYV1oIZOnTrpzRcUOHF34sSJODorIiKi0HN01jcREVG4Y6AmIiIyGAM1ERGRwYxYo46PWKieiIiigyNqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBGKiJiIgMxkBNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjUw4i8hubzFA4KWLY65kjaiIiIoMxUBMRERmMU9/k2OkgIqL4gCNqIiIigzFQExERGYxT337K3eOHSL92YljdOD0XIiIKPxxRExERGYyBmoiIyGCc+qawxkx1CqfXhhPPmfzHETUREZHBGKiJiIgMxkBNRERkMCMCdUREhOTOnVuSJUsmZcuWla1bt0b5/V9//bUULFhQv79IkSLy448/xtm5EhERxatAvWDBAunatav069dPdu7cKcWKFZOaNWvKhQsXfH7/pk2bpEmTJtKmTRvZtWuX1K9fX2+//vprnJ87ERFR2Afq0aNHS7t27aRVq1ZSqFAhmTRpkiRPnlymT5/u8/vHjh0rtWrVku7du8szzzwjAwcOlBIlSsj48ePj/NyJiIjCenvW3bt3ZceOHdKzZ0/XsYQJE0q1atVk8+bNPn8GxzECd4cR+JIlS4J+vkRE5EP/JyL/Wp5ccXkmYSmkgfrSpUty//59yZw5s8dxfH7o0CGfP3Pu3Dmf34/jvty5c0dvtuvXr+u/N27cCMBvIPLgzq1IvxbVY9y/fT9WPxcIhfutiPRrvw6oaeQ5x1YozznK10YCy9jnObLXB18boRfqc47sNc3Xc8zZ92NZkT93LlYInT59Gmdobdq0yeN49+7drTJlyvj8mSRJklhz5871OBYREWFlypTJ5/f369dPH4M33njjjTfexLDbqVOnHhkrQzqizpAhgyRKlEjOnz/vcRyfZ8mSxefP4HhMvh/T6u5T5Q8ePJArV65I+vTpJUGCBBJIuELKmTOnnDp1SlKnTi1OwHOOGzznuMFzjhs8Z/9hJP3nn39KtmzZHvm9IQ3Ujz32mJQsWVJWr16tmdt2IMXnnTp18vkz5cuX16+///77rmM//fSTHvcladKkenOXJk0aCSa8CEx4IcQEzzlu8JzjBs85bvCc/fPEE1Gs7ZtU6xuj3ZYtW0qpUqWkTJkyMmbMGLl586ZmgUOLFi0ke/bsMnToUP28S5cuUqVKFRk1apTUrVtX5s+fL9u3b5cvvvgixL8JERFR4IU8UDdq1EguXrwoffv21YSw4sWLy/Lly10JYydPntRMcFuFChVk7ty50rt3b+nVq5c89dRTmvFduHDhEP4WREREYRqoAdPckU11r1mz5qFjb7zxht5Mgyl2FG7xnmo3Gc85bvCc4wbPOW7wnONWAmSUxfFjEhERkVMqkxEREVHkGKiJiIgMxkBNRERkMAZqIiIigzFQx9I///wjs2bNeqhKGhERUSAx69sPaMd58OBBefLJJ8UpUFwGvbwrV64sTpI3b17Ztm2bln51d+3aNW1zeuzYMQm17777LtrfW69evaCeS3yGRj/79u3Tv8u0adOG+nQcKybNJ0yp9OVt3bp1EhWnvA8asY/aqVBJbffu3Y4K1OgehjaiOGdUf0PgRuU30504cULfgL2hM9rp06fFBHYZXBtqybtfB7vXlvf1u5hg5syZWoMfVf/go48+0qp/6BU/b948I1/rKCdcpEgRvQDF84rKhZs2bdIL6aVLl8oLL7wQ6lN0JJRajm4/BFNfzy/4+L93wt+hNwZqP3To0EFLoKLIO2qWp0iRwuPrRYsWFdOgihsqwX311Vf6powCAAjceJN79dVXJUmSJGIS91HqihUrPGrj4o8Mdd9z584tJkCdetuqVavk448/liFDhrjq0KOXOirq4ZipcG4TJ050nW9ERIR8/vnnGvA++OAD+eabb8Q0ixYtkrfeeks//v777+X48ePaJhev8U8++UQ2btwoJsJ5L1y4UKsv3r171+NrO3fulFD7+eefPS6Ue/ToIW+//bbH6xnvIXZ5ZxNdvXrV4/N79+7Jrl27pE+fPjJ48GBxjBh0pSQvCRIkeOiWMGFC179OsGPHDqtTp05WsmTJrAwZMljvv/++deTIEcvk59i+PfbYY9bTTz9tff/995Zpnn32WWv9+vUPHV+3bp1VsGBBy1SPP/649ccff+jHH330kdW8eXP9+Ndff9XXh4mSJk3qahXYrl07q0uXLvrxsWPHrFSpUlkmGjt2rJUyZUr928Pr+J133rGqVatmPfHEE1avXr0s07z00ksPtReGOXPmWFWqVLGcZs2aNVaJEiUsp2AymR9w5e59w1qp/a/pzp49q53HcEO70Tp16ujaHqY5MYoyZZSKG6ZcMRNgf44bpr0PHz4sL7/8spjm6NGjPru0YUYAoxNTpUyZUi5fvqwfr1y5UqpXr64fJ0uWTG7fvi0mQl+AAwcO6AwL+gTY53zr1i19XZtowoQJuqTw73//W7sIYokBf4edO3fW5SnTYPSMxknecGzr1q3iNJkzZ9b3DscI9ZUCxa27d+9aixYtsurWrWslSZLEKlmypDVx4kTr+vXrru/55ptvrDRp0lgmnTOu6E0a6T9KpUqVrOrVq1vnzp1zHcPHNWrUsCpXrmyZqmnTpjrSaNOmjZU8eXLr0qVLevzbb7/VWQIT9evXT0eimKnIlSuX9ffff+vxadOmWeXKlbNMnbk4ceKEfpwxY0Zr9+7d+jFe4+nSpbNMg5mr7t27P3Qcx/A1U+3Zs8fjhud52bJlOgvw/PPPW07BNWo/YR1s0qRJOorGVSdGfmjVmSdPHl3zNU3WrFl1NNqkSRO9Eka3Mm8vvvhi0Ht2xwTWzffu3StOMm3aNHnttdckV65c2qwekMtgd3szFdaksY6Oc/3Pf/7jyrLfsWOHvmZM1L9/f+2eh3NGsx676QJG01hXNVGWLFnkypUr+n6B18iWLVukWLFi+j5i4kYczLC9/vrrsmzZMilbtqwew/vHb7/9pq8TUxUvXvyhpE4oV66cTJ8+XZyC27P8gKQbtOdE1ikSE3799VfdRvTll19qkoV7MoZJFxZ4M8NUppMgkQlvwMOGDROnwJ8WpjOR2ATPPPOMJu5FN5OWYu7vv/92xGu7bdu2egGHZE5cHHXv3l2ef/552b59u17g4ULPNP/73//0PQ9bUu3Xc/v27V0Xoib6448/PD5Hy+SMGTM64jXijoHaD1jLRZYstuWkSpVK9uzZo4EaARvbAi5duiQmQcbj448/rlvKnNa/+7333tMCMxiR+sqwHz16tJjCyc8zrF+/XiZPnqx5Fl9//bVu38MFHmaJKlasKKbB2jT+DjGzhQJER44c0b9DZPZiRwB2NJjGzrNInPj/JjXnz5+vW8rw+n7nnXd03dqk13OtWrX0+cX5UdxjMpkfME313HPPPXQcI7+bN2+KaTCFjGk2p+wddIeLHxQ2wQUR3oixxcK+ISCaxMnPM6Yxa9asqRca2CKEhD1AgpOp28owm4VZrOHDh3sEOFwkTZ06VUyEkZ0dpKFx48Yybtw4vSA1KUg7denJ3dq1a+WVV16R/Pnz6w3FhnAx6iihXiR3smeeecZasmSJfoytFkePHtWPx40bZz333HOWiaZOnWrVqVPHunz5cqhPJaw59XkuXry4NXPmzIde0zt37rQyZ85smShfvnzWqlWrHjrngwcPGpUU6S5PnjzW22+/7Up8s128eFG/Zhps2/z4448tp/nqq6+sxIkTW2+++aZuicMNHyORFlvLnILJZH5AsZOOHTvquhhWEJBcgepNKABg6pX8+PHj5ffff5ds2bJpIov3FLIJhRais1YGOXLkEFM59XnGlhVfZRWxrQzlWk2EynQYKXnD1DKmbU2ELXoYUVeqVEmL+iC5DDAL472uakpvAyRfoZCP6UtP3rMtmGlBjosNW+BwvgMHDpSmTZuKEzBQ+5kQgilCZMlizyb+0/HGPHbsWJ3KMpF3mUunwJvuoEGDZNSoUfLXX3/pMUyDf/jhh1p9ClOJJnHq84yAgQsM72pvGzZs0HVfU3NFMJXpXd4Ulb98LU2ZAAmF2PPdrVs3DXzYCVC6dGkxfekJsPTkzuTkyGPHjum0tzdMf/fq1UscI9RD+nBx8+ZN6/z586E+jbDVo0cP3W86YcIE157IiIgIPWZiJSenGjJkiFWoUCFry5YtWtUL1dVmz56tzzOWdEyE5Sfsox42bJju/R4xYoTVtm1brfi1cuVKy0SorGe/X+C1jX3VmKbFXnunVDV0gnz58lmTJk166DhqR+TPn99yCgZqP9y6dUsDtA0FDD7//HNrxYoVlsmuXr1qTZkyRd8g7DVUlBL93//+Z5kqa9asWnTD15t0tmzZQnJO4ejBgwfWoEGDrBQpUrhKtaK8bO/evS2ToTQrSnDiggJBD8UsTP47RDB2v7BHkMbz3KpVKwbqAJowYYJesLVv396aNWuW3lCuFWVnfQVwU3F7lh9q1Kihex6xlxDrdwUKFNCMTWzLwhrIu+++K6ZB9ib28tqlLLEmiSlNTN+jOQC2QJkI+x5x7k8//bTHcZw/ihqYVt4Sa40oEhFZ0wUUuzAZzhdT4FhmwNQySotS4GCp5ty5c5IpUybXMRRMatCggZbKNXHHAPZ4R/Z6NrFZi23x4sW6ZOa+/xv71k0sSBWpUF8pOFn69Om1WQFghFq0aFHr/v371sKFC41tvFC1alVXKUD3DNmNGzdaTz75pGWqMmXKWO+9995Dx9HUoGzZspZp+vTpo7MAI0eO1JHSwIEDtSwnXjPIPKXAwfP6888/W+EAU99oGGGaefPmaab0yy+/rCNU/IvSoVhyQPa6qVq0aGGtXbvWcjoG6gB1GnrjjTes/v3768cnT57Ur5koderU1u+///5QoMa0PaaDTIU3L0zHYktc69at9YaP8Ttg2tM0efPmtZYuXaof4xzt5xxBukmTJpap/vrrL53mLl++vK7vYauQ+81E9erV09dujhw5rG7dulm7du2yTDdgwABr9erVPp9/fM00RYoUscaPH+/xvoFlEnQr69u3r2WqV199VS8wsB49ePBg6/Tp05YTMVD7+eLFGy8CMwLgpk2b9Pj27duN3XOKNTzsifUO1Ei6wRudyfBHhsSx1157TW+ffPKJsX94SGqyL+KyZMmiOQCA5xuvFVM1btxYZwLQ4hL5FmPGjPG4merKlSvW5MmTtdkC1niREIc35uPHj1smstu0jho1yuO4qclkeD3bzyWahuzdu1c/PnDggL6+TXbhwgV9njHjiT3VtWrV0llPNPtxCgZqP3z99dd6tYY/LCSyuGfO4sVg6jRh/fr19UWKQI2evQgoKNBi9/E1RYMGDVxdvVCEw7s4hMkwLYjMaUBi09ChQ/Xj+fPn68WSqTCVuWHDBsvJ0Jt6+PDhuvyUKFEiy9RAjdcClkIwdXznzh2jA3X27NldwRkDFLs3NQYnJl94esMFM5bLsByF/uoo5OKErnwM1H46e/asjlCxNm375ZdftCqSia5du6YXFajYhDexnDlz6sUGWi9i2s0kOK8zZ874zJI1Hao4YUQHeEPGlTym3zCKMrnCU+7cuXWU5FS4AF28eLH1+uuv65uxqTsC7O1ZWBLBEg6WGvC5qYEayzX26P/TTz/Vi01sgUNeCy6oneDMmTO6ha9AgQK6jIb1a+Ts4G9z9OjRlsmY9R2PqmV5F7BAFjWyelHIAJngpilatKieG9putmrVSmshp06d2uf3tmjRQkyGNoZ20wVfBRhMMXv2bPn222+1+1vy5MnFKdCpbu7cuVqrHMVxsBujWbNm8tJLLxlZkAMtOM+ePatZ3zdu3JA333xT9u/fr40vUIzDtKxv7FJABUYUdMLzi2pf9usZO0bSpk0rJrp3755WfpsxY4asXLlS31NQqArFqez3EmSFt27dWq5evSqmYqCOR9WyAD17TW5L527jxo36XB49elTfKPDc+nrTxTHTtzuZDNW73J9XbMvC2wKqk6Ehg+mlT9HdC///6PCE4IwLIbsntVO2Z+G9BO1y0UYSH5sWqJ0qQ4YM+nyil3q7du10K6c3bK3F3wCaLJmKJUT9gGCMvrHokYxesvZIFY3scfWJOrOmwZsvWhW+9dZb0rBhQ2OvhAHPKUai9hsbShe67zs1GbpnodVplSpV9N98+fKJqZxa7tSGvzf0WE+TJo04BUZ4qGVgw+sbM0YIGOvWrRPTYMYKM1uoA2/ya9kbahngtRFV/2m8bkwO0sARtR8wDWRPVbnD1GGHDh20WYBp0BYSU4Tof4vCChiFIGibOArB9CXaF2KKClOxmB5EbXUnwBQy3nDXrFmjI1SM+hC07cDNvr7B4bQlKKfAdDFez+6vZftClK/l4GOgjkfVstzhvx1BxHtdDx1yTIEqb+gklDVrVo81PafBeaMn7tKlS2XBggVGT21u27ZNz69s2bIex3/55Rf9PyhVqpSYxilLUBgx/+tf/9L3DXwcGSxDoC+1iTD4QMDG6xk3zHLh79O+QKLgYKD2A97McPP+o8MfGd7w7Glb02HdsU2bNnrRYVIAcXoyGTqqYSkEF0RIdsJsBsoXYiSCKTkTlSlTRj766CNdFvEuEfnZZ59pwDZNz549dQlqwIABDy1BYV3SlCWoPHnyaBnO9OnT68dRBWp0fTKR/ZrG6xmva7x3oMQsXtsUPAzUfsAVZd26dXU9snz58q56vUjY+vHHH7XXrKlwBYzRNG5oYYfzRyIO6pabAlml6PntxGSyChUqeARmTBFifc/knABATW9csHm3tMQaHi6c/vzzTzGNE5eg3NlvwSZmp9vQEhKB2X5N21PfTnhNhwMGaj+dOXNGIiIi5NChQ/o5XsR4c8Cbh4kmT56swRlXxThXBGdsVfDu5euEJgYmS5cunZ4zGrfgDQ037yUSE2G0hyl6+8LT/aIJF6UmbmFx6hIUZgEws/Lbb7/p51jrReY31oNNg9dyxowZ5YMPPtAlMie8lsMJA3U8g61Z2KqAAF2sWDFxCqxVo2sPLjQwLfj1119rUstXX32l04jIZDcJ/qz27dunoxDMvGBdD2vuGIlgKh9TsibCawNr6hiN2lnJ2L6CzHBcJKF7kmmcuATVt29f7bCHc3SfjRs/frwGw08//VRMsmfPHn0d4/W8fv1612vZSRehTsZAHUO4co8uTBWaBv/dGE07JeDZkPDWvHlzvcDAuR44cECnZ/HGhmUG3EyF53zHjh16rnPmzDE6mQzTxJjOvHz5sm4Vgt27d0vmzJnlp59+MnIPfmRLULiwW7ZsmZFLUBid4sICF0bu5s2bp8EbrXJNhsCN2QDTX8/hgvuoYwhTaVhLetT1Db7HxBcvkoLsgIdEkDt37ujx69evy5AhQ4wNeMjqxTokksawtcyG5CF8zTR4bjH6wA0XRljbLVKkiL4JYyRiKly04WIUb8B4M8Z2OCTyIaB4Fz8xBZ5PTHOjWIjdcxjTsyYvQaFilq8M+pIlS8o///wjpsH7Hdan3V/TqKiGwYjJr+dwwRF1LKZgo8vEdV+MkjC1hoCH5Cy8GWNkij/C2rVr6zqwiVDOEqNoFGxxP2/MCiDrFAVmTJI4cWJ9ru290xiluhe4oMDC/z8uMC5cuKAjPHfeSWYmwAUbLnww/e2uW7duuqaOvBeTIGEMW9+wXGZPeWOmwklFZpyMI+oYcg++Q4cO1SlB1Il1h73IKCby8ccfi2kw8kDQ8IYggrVIU2XJkkWLLSBQu8OVvXeGcqhhJgUzF3gjc2JGLJKbsP3GV9DD2qppli9frheemK73HneYOrNlJ5Oh/nS5cuX0c2x9w3Q9fhfsdrB5B/NQFfDB6zmy7ZEUXAzUAcig9vbss89K48aNjQzUTgp47pB81aVLF70Iwpsvsu2xDokRSJ8+fcQkKAyCKmqYhnVaoJ4yZYq8++67WiMZrxX3LUP42MRAjdEpykTi3HDh7ATYEokaAYDth4DnHDd8zWbKli3kANhY/S0EQta3KwwkTZpU+zl7O3r0qH7NROiVXahQIe2VnCpVKmv9+vXW7NmztW3duHHjLFM9ePDAGjRokLanQ4tA3NDGsHfv3paJSpYsaa1atcpymly5cmkrQCfB6xjtIil40MZ3wIAB2nsabThxQ+9ytLx0b/FLwcFA7Qf0F/7qq68eOj5r1iwrT548lomcFvC83blzx9q/f7/2/P7zzz8tUy1btswqXry49f3332sf3OvXr3vcTA56uNB0klatWllTp04N9WmEtR49eujF/IQJE6w9e/boLSIiQo/16tUr1KcX9phM5gf0ZMVtxIgR2vcWVq9erSUYUWcYpQ1NdffuXZ0CR4IIkrFQkYoCx72+tPv0Jf7cTF43RSnZ0qVLG1WhLjplLTH1jS1PyKz3zk7v3LlzyM4tXDi9+pvTcY3aD927d9cEFrxQEfjsKklYmzY5SAMKFiBAU3AgGcuJ8ufPr2v+KBLilKCHvcdIysLfHrYOea+rm3jOToMSvQULFnzoOI6ZVr43HHFEHQAYlSJxCHtOUQbQtHaRRNHlxGYRSHpDMO7Ro4cxnbLCjROrv4UTBmqiIMF2N2zBsYtwYDcAtvJxP3Xg66ojWOTLly/UpxK2nNyAKBwwUBMFAdoZ1qxZU2dZ0DoSEExQzALTtPbWHBNgz+7AgQMlRYoUHvt3fY2o0fPZNCjgg/VpdHii4MD+bhTx8dWACJXUEMApeBioiYIAIwys92JfMt7gAG9o6IyE6WM06TAFmoQsXrxYq0zh46gC9X//+18xDaa9Z82apVWzUNLSe13dhIIhTofaAGjW4t29Djk6OGZqcmS4YKAmCgKMpFGW1TsBB2VQUeMZmcoUGE68uHCayNrMoqQyklJv3rwZsnOLD5j1TRQEKLWI6ULvQI01PdQqp8Bxaoa9E9hLIXZVOtTct2EUjbKnaFREwcVATRQEjRo10j3JI0eOlAoVKuixjRs36pY+79aGRKbCrJB7f3Vs67ThYyw3oIwvBRenvokCBN2bChcurNOE2FePoIwiEXbbQqydoo72sGHDuIWPHAWtTseOHcumHCHCQE0UhIQbNDhBljfWqu2mC9g+5D51SEQUHZz6JgoQZE0fP35cA/WJEye0RSQCMyp8ERHFFgM1UYC8/vrrUqVKFcmaNasm3yC7G6NsX0ys8EVEZmKgJgqQL774Ql577TVtdoK9veihzQxvIvIX16iJgpR8g7rIDNRE5C8GaiIiIoOx1QwREZHBGKiJiIgMxkBNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIhJz/T84jaWarKztEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制不同温度系数下的概率分布\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n"
     ]
    }
   ],
   "source": [
    "# 温度系数为0.1时\n",
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "# 温度系数为5时\n",
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.3.2 Top-k 采样"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top possitions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# 取前k个概率最大的词\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top possitions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# 将非前k个logits设为-inf\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# top k的概率\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 优化文本生成功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加topk和temperature参数的文本生成函数\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 取context_size个词\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # 取最后一个词的预测logits\n",
    "        # 实际的场景下，会通过kv cache的方式来减少冗余计算\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # top k 采样\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        \n",
    "        # 温度校正\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "source": [
    "# 新的生成策略测试\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在Pytorch中加载并保留权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型参数\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数，同时，保存优化器参数\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型参数和优化器参数\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 从OpenAI导入训练好的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/LLMs-from-scratch-CN/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 下载OpenAI的预训练模型\n",
    "from gpt_download import download_and_load_gpt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 41.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 901kiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 18.2kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:24<00:00, 3.44MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 4.12MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 502kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 484kiB/s] \n"
     ]
    }
   ],
   "source": [
    "# 加载124M模型\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义模型\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型参数前，进行shape检查\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载模型参数\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # 加载embedding层\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "    # 加载transformer层\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # 加载带bias的qkv\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        # 加载输出层\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 加载ff层\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 加载norm层\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "    # 加载最后的norm层\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # 加载输出层\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型加载\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more efficient and efficient processes, like in the car's oil and gas operation,\" the study said. To see if that\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
